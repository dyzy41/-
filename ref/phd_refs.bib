@article{Abdelfattah2023CDULCU,
	title        = {CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification},
	author       = {Rabab Abdelfattah and Qing Guo and Xiaoguang Li and Xiaofeng Wang and Song Wang},
	year         = 2023,
	journal      = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {1348--1357},
	xurlx          = {https://api.semanticscholar.org/CorpusID:260334889}
}
@article{Alcantarilla2016StreetviewCD,
	title        = {Street-view change detection with deconvolutional networks},
	author       = {Pablo Fern{\'a}ndez Alcantarilla and Simon Stent and Germ{\'a}n Ros and Roberto Arroyo and Riccardo Gherardi},
	year         = 2016,
	journal      = {Autonomous Robots},
	volume       = 42,
	pages        = {1301--1322},
	xurlx          = {https://api.semanticscholar.org/CorpusID:35129401}
}
@article{AlRahhal2022MultilanguageTF,
	title        = {Multilanguage Transformer for Improved Text to Remote Sensing Image Retrieval},
	author       = {Mohamad Mahmoud Al Rahhal and Yakoub Bazi and Norah A. Alsharif and Laila Bashmal and Naif A. Alajlan and Farid Melgani},
	year         = 2022,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 15,
	pages        = {9115--9126},
	xurlx          = {https://api.semanticscholar.org/CorpusID:253252302}
}
@article{Audebert2017BeyondRV,
	title        = {Beyond RGB: Very High Resolution Urban Remote Sensing With Multimodal Deep Networks},
	author       = {N. Audebert and B. L. Saux and S{\'e}bastien Lef{\`e}vre},
	year         = 2017,
	journal      = {ArXiv},
	volume       = {abs/1711.08681},
	xurlx          = {https://api.semanticscholar.org/CorpusID:10008238}
}
@article{b_huang_remote-sensing_2024,
	title        = {Remote-Sensing Image Change Detection Based on Adjacent-Level Feature Fusion and Dense Skip Connections},
	author       = {{B. Huang} and {Y. Xu} and {F. Zhang}},
	volume       = 17,
	pages        = {7014--7028},
	doi          = {10.1109/JSTARS.2024.3374290},
	issn         = {2151-1535},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	date         = 2024
}
@article{c_tao_hasnet_2025,
	title        = {{HASNet}: A Foreground Association-Driven Siamese Network With Hard Sample Optimization for Remote Sensing Image Change Detection},
	author       = {{C. Tao} and {D. Kuang} and {Z. Huang} and {C. Peng} and {H. Li}},
	volume       = 63,
	pages        = {1--16},
	doi          = {10.1109/TGRS.2025.3545760},
	issn         = {1558-0644},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2025
}
@article{chen_remote_2022,
	title        = {Remote Sensing Image Change Detection with Transformers},
	author       = {Chen, Hao and Qi, Zipeng and Shi, Zhenwei},
	volume       = 60,
	pages        = {1--14},
	doi          = {10.1109/TGRS.2021.3095166},
	issn         = {0196-2892, 1558-0644},
	xurlx          = {http://arxiv.org/abs/2103.00208},
	xurlxdate      = {2023-10-23},
	abstract     = {Modern change detection ({CD}) has achieved remarkable success by the powerful discriminative ability of deep convolutions. However, high-resolution remote sensing {CD} remains challenging due to the complexity of objects in the scene. Objects with the same semantic concept may show distinct spectral characteristics at different times and spatial locations. Most recent {CD} pipelines using pure convolutions are still struggling to relate long-range concepts in space-time. Nonlocal self-attention approaches show promising performance via modeling dense relations among pixels, yet are computationally inefﬁcient. Here, we propose a bitemporal image transformer ({BIT}) to efﬁciently and effectively model contexts within the spatial-temporal domain. Our intuition is that the high-level concepts of the change of interest can be represented by a few visual words, i.e., semantic tokens. To achieve this, we express the bitemporal image into a few tokens, and use a transformer encoder to model contexts in the compact tokenbased space-time. The learned context-rich tokens are then feedback to the pixel-space for reﬁning the original features via a transformer decoder. We incorporate {BIT} in a deep feature differencing-based {CD} framework. Extensive experiments on three {CD} datasets demonstrate the effectiveness and efﬁciency of the proposed method. Notably, our {BIT}-based model signiﬁcantly outperforms the purely convolutional baseline using only 3 times lower computational costs and model parameters. Based on a naive backbone ({ResNet}18) without sophisticated structures (e.g., {FPN}, {UNet}), our model surpasses several state-of-the-art {CD} methods, including better than four recent attention-based methods in terms of efﬁciency and accuracy. Our code is available at https://github.com/justchenhao/{BIT} {CD}.},
	journaltitle = {{IEEE} Trans. Geosci. Remote Sensing},
	date         = 2022,
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {2103.00208 [cs]},
	keywords     = {Computer Science - Computer Vision and Pattern Recognition},
	file         = {Chen 等 - 2022 - Remote Sensing Image Change Detection with Transfo.pdf:files/70/Chen 等 - 2022 - Remote Sensing Image Change Detection with Transfo.pdf:application/pdf}
}
@article{chen_spatial-temporal_2020,
	title        = {A Spatial-Temporal Attention-Based Method and a New Dataset for Remote Sensing Image Change Detection},
	author       = {Chen, Hao and Shi, Zhenwei},
	volume       = 12,
	number       = 10,
	pages        = 1662,
	doi          = {10.3390/rs12101662},
	issn         = {2072-4292},
	xurlx          = {https://www.mdpi.com/2072-4292/12/10/1662},
	xurlxdate      = {2023-10-23},
	abstract     = {Remote sensing image change detection ({CD}) is done to identify desired signiﬁcant changes between bitemporal images. Given two co-registered images taken at different times, the illumination variations and misregistration errors overwhelm the real object changes. Exploring the relationships among different spatial–temporal pixels may improve the performances of {CD} methods. In our work, we propose a novel Siamese-based spatial–temporal attention neural network. In contrast to previous methods that separately encode the bitemporal images without referring to any useful spatial–temporal dependency, we design a {CD} self-attention mechanism to model the spatial–temporal relationships. We integrate a new {CD} self-attention module in the procedure of feature extraction. Our self-attention module calculates the attention weights between any two pixels at different times and positions and uses them to generate more discriminative features. Considering that the object may have different scales, we partition the image into multi-scale subregions and introduce the self-attention in each subregion. In this way, we could capture spatial–temporal dependencies at various scales, thereby generating better representations to accommodate objects of various sizes. We also introduce a {CD} dataset {LEVIR}-{CD}, which is two orders of magnitude larger than other public datasets of this ﬁeld. {LEVIR}-{CD} consists of a large set of bitemporal Google Earth images, with 637 image pairs (1024 × 1024) and over 31 k independently labeled change instances. Our proposed attention module improves the F1-score of our baseline model from 83.9 to 87.3 with acceptable computational overhead. Experimental results on a public remote sensing image {CD} dataset show our method outperforms several other state-of-the-art methods.},
	journaltitle = {Remote Sensing},
	date         = {2020-05-22},
	langid       = {english},
	file         = {Chen 和 Shi - 2020 - A Spatial-Temporal Attention-Based Method and a Ne.pdf:files/66/Chen 和 Shi - 2020 - A Spatial-Temporal Attention-Based Method and a Ne.pdf:application/pdf}
}
@inproceedings{chen2018encoder,
	title        = {Encoder-decoder with atrous separable convolution for semantic image segmentation},
	author       = {Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
	year         = 2018,
	booktitle    = {Proceedings of the European conference on computer vision (ECCV)},
	pages        = {801--818}
}
@article{Chen2020ASF,
	title        = {A Simple Framework for Contrastive Learning of Visual Representations},
	author       = {Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey E. Hinton},
	year         = 2020,
	journal      = {ArXiv},
	volume       = {abs/2002.05709},
	xurlx          = {https://api.semanticscholar.org/CorpusID:211096730}
}
@article{Chen2021FCCDNFC,
	title        = {FCCDN: Feature Constraint Network for VHR Image Change Detection},
	author       = {Pan Chen and Danfeng Hong and Zhengchao Chen and Xuan S. Yang and Baipeng Li and Bing Zhang},
	year         = 2021,
	journal      = {ArXiv},
	volume       = {abs/2105.10860},
	xurlx          = {https://api.semanticscholar.org/CorpusID:235166250}
}
@article{Chen2021VisualGPTDA,
	title        = {VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning},
	author       = {Jun Chen and Han Guo and Kai Yi and Boyang Albert Li and Mohamed Elhoseiny},
	year         = 2021,
	journal      = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {18009--18019},
	xurlx          = {https://api.semanticscholar.org/CorpusID:235351128}
}
@article{Chen2022ASA,
	title        = {A Self-Supervised Approach to Pixel-Level Change Detection in Bi-Temporal RS Images},
	author       = {Yuxing Chen and Lorenzo Bruzzone},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--11},
	xurlx          = {https://api.semanticscholar.org/CorpusID:252053311}
}
@article{Chen2022SemanticAwareDR,
	title        = {Semantic-Aware Dense Representation Learning for Remote Sensing Image Change Detection},
	author       = {Hao Chen and Wenyuan Li and Songhang Chen and Zhenwei Shi},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--18},
	xurlx          = {https://api.semanticscholar.org/CorpusID:249151913}
}
@article{chen2023continuous,
	title        = {Continuous cross-resolution remote sensing image change detection},
	author       = {Chen, Hao and Zhang, Haotian and Chen, Keyan and Zhou, Chenyao and Chen, Song and Zou, Zhengxia and Shi, Zhenwei},
	year         = 2023,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	publisher    = {IEEE},
	volume       = 61,
	pages        = {1--20}
}
@article{Cheng2022ISNetTI,
	title        = {ISNet: Towards Improving Separability for Remote Sensing Image Change Detection},
	author       = {Gong Cheng and Guangxing Wang and Junwei Han},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--11},
	xurlx          = {https://api.semanticscholar.org/CorpusID:248733960}
}
@article{Chollet2016XceptionDL,
	title        = {Xception: Deep Learning with Depthwise Separable Convolutions},
	author       = {François Chollet},
	year         = 2016,
	journal      = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {1800--1807},
	xurlx          = {https://api.semanticscholar.org/CorpusID:2375110}
}
@article{d_sidekejiang_mldfnet_2025,
	title        = {{MLDFNet}: A Multilabel Dual-Flow Network for Change Detection in Bitemporal Remote Sensing Images},
	author       = {{D. Sidekejiang} and {P. Zheng} and {L. Wang}},
	volume       = 18,
	pages        = {4867--4880},
	doi          = {10.1109/JSTARS.2025.3530146},
	issn         = {2151-1535},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	date         = 2025
}
@article{Dai2017DeformableCN,
	title        = {Deformable Convolutional Networks},
	author       = {Jifeng Dai and Haozhi Qi and Yuwen Xiong and Yi Li and Guodong Zhang and Han Hu and Yichen Wei},
	year         = 2017,
	journal      = {2017 IEEE International Conference on Computer Vision (ICCV)},
	pages        = {764--773},
	xurlx          = {https://api.semanticscholar.org/CorpusID:4028864}
}
@inproceedings{dao_transformers_2024,
	title        = {Transformers are {SSMs}: Generalized Models and Efficient Algorithms Through Structured State Space Duality},
	author       = {Dao, Tri and Gu, Albert},
	booktitle    = {International Conference on Machine Learning ({ICML})},
	date         = 2024
}
@article{Daudt2018FullyCS,
	title        = {Fully Convolutional Siamese Networks for Change Detection},
	author       = {Rodrigo Caye Daudt and B. L. Saux and Alexandre Boulch},
	year         = 2018,
	journal      = {2018 25th IEEE International Conference on Image Processing (ICIP)},
	pages        = {4063--4067},
	xurlx          = {https://api.semanticscholar.org/CorpusID:52189223}
}
@article{Daudt2018MultitaskLF,
	title        = {Multitask learning for large-scale semantic change detection},
	author       = {Rodrigo Caye Daudt and B. L. Saux and Alexandre Boulch and Yann Gousseau},
	year         = 2018,
	journal      = {Comput. Vis. Image Underst.},
	volume       = 187,
	xurlx          = {https://api.semanticscholar.org/CorpusID:201248795}
}
@article{Deng2009ImageNetAL,
	title        = {ImageNet: A large-scale hierarchical image database},
	author       = {Jia Deng and Wei Dong and Richard Socher and Li-Jia Li and K. Li and Li Fei-Fei},
	year         = 2009,
	journal      = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {248--255},
	xurlx          = {https://api.semanticscholar.org/CorpusID:57246310}
}
@article{Deng2018ArcFaceAA,
	title        = {ArcFace: Additive Angular Margin Loss for Deep Face Recognition},
	author       = {Jiankang Deng and J. Guo and Stefanos Zafeiriou},
	year         = 2018,
	journal      = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {4685--4694},
	xurlx          = {https://api.semanticscholar.org/CorpusID:8923541}
}
@article{Deng2021TransVGEV,
	title        = {TransVG: End-to-End Visual Grounding with Transformers},
	author       = {Jiajun Deng and Zhengyuan Yang and Tianlang Chen and Wen-gang Zhou and Houqiang Li},
	year         = 2021,
	journal      = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {1749--1759},
	xurlx          = {https://api.semanticscholar.org/CorpusID:233296838}
}
@inproceedings{Devlin2019BERTPO,
	title        = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author       = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
	year         = 2019,
	booktitle    = {North American Chapter of the Association for Computational Linguistics},
	xurlx          = {https://api.semanticscholar.org/CorpusID:52967399}
}
@article{Ding2023AdaptingSA,
	title        = {Adapting Segment Anything Model for Change Detection in VHR Remote Sensing Images},
	author       = {Lei Ding and Kun Zhu and Daifeng Peng and Hao Tang and Kuiwu Yang and Lorenzo Bruzzone},
	year         = 2023,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--11},
	xurlx          = {https://api.semanticscholar.org/CorpusID:261531371}
}
@article{sam_feature_extraction,
	title        = {Integrating SAM With Feature Interaction for Remote Sensing Change Detection},
	author       = {Zhang, Da and Wang, Feiyu and Ning, Lichen and Zhao, Zhiyuan and Gao, Junyu and Li, Xuelong},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	number       = {},
	pages        = {1--11},
	doi          = {10.1109/TGRS.2024.3483775},
	keywords     = {Adaptation models;Computational modeling;Feature extraction;Transformers;Remote sensing;Image segmentation;Biological system modeling;Semantics;Data models;Training;Change detection (CD);remote sensing (RS);vision foundation model (VFM)}
}
@article{self_sam,
	title        = {Integrating Deep Change Vector Analysis and SAM for Class-Specific Change Detection},
	author       = {Saha, Sudipan and Awadhiya, Kanishk},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = {},
	number       = {},
	pages        = {1--12},
	doi          = {10.1109/JSTARS.2025.3591017},
	keywords     = {Foundation models;Semantics;Semantic segmentation;Feature extraction;Earth;Remote sensing;Computational modeling;Vectors;Transformers;Training;Change detection;deep learning;earth observation;foundation models}
}
@inproceedings{seganychange,
	title        = {Segment Any Change},
	author       = {Zheng, Zhuo and Zhong, Yanfei and Zhang, Liangpei and Ermon, Stefano},
	year         = 2024,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 37,
	pages        = {81204--81224},
	xurlx          = {https://proceedings.neurips.cc/paper_files/paper/2024/file/9415416201aa201902d1743c7e65787b-Paper-Conference.pdf},
	editor       = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang}
}
@article{dong_changeclip_2024,
	title        = {{ChangeCLIP}: Remote sensing change detection with multimodal vision-language representation learning},
	author       = {Dong, Sijun and Wang, Libo and Du, Bo and Meng, Xiaoliang},
	volume       = 208,
	pages        = {53--69},
	doi          = {10.1016/j.isprsjprs.2024.01.004},
	issn         = {0924-2716},
	xurlx          = {https://www.sciencedirect.com/science/article/pii/S0924271624000042},
	abstract     = {Remote sensing change detection ({RSCD}), which aims to identify surface changes from bitemporal images, is significant for many applications, such as environmental protection and disaster monitoring. In the last decade, driven by the wave of artificial intelligence, many change detection methods based on deep learning emerged and have achieved essential breakthroughs. However, these methods pay more attention to visual representation learning while ignoring the potential of multimodal data. Recently, the foundation vision-language model, i.e. {CLIP}, has provided a new paradigm for multimodal {AI}, demonstrating impressive performance on downstream tasks. Following this trend, in this study, we introduce {ChangeCLIP}, a novel framework that leverages robust semantic information from image-text pairs, specifically tailored for Remote Sensing Change Detection ({RSCD}). Specifically, we reconstruct the original {CLIP} to extract bitemporal features and propose a novel differential features compensation module to capture the detailed semantic changes between them. Besides, we proposed a vision-language-driven decoder by combining the results of image-text encoding with the visual features of the decoding stage, thereby enhancing the image semantics. The proposed {ChangeCLIP} achieved state-of-the-art {IoU} on 5 well-known change detection datasets, {LEVIR}-{CD} (85.20\%), {LEVIR}-{CD}+ (75.63\%), {WHUCD} (90.15\%), {CDD} (95.87\%) and {SYSU}-{CD} (71.41\%). The code and the pretrained models of {ChangeCLIP} will be publicly available on https://github.com/dyzy41/{ChangeCLIP}.},
	journaltitle = {{ISPRS} Journal of Photogrammetry and Remote Sensing},
	date         = {2024-02-01},
	keywords     = {Change detection, Remote sensing, Multimodal artificial intelligence, Vision-language representation learning}
}
@article{Dong2021AMF,
	title        = {A Multi-Level Feature Fusion Network for Remote Sensing Image Segmentation},
	author       = {Sijun Dong and Zhengchao Chen},
	year         = 2021,
	journal      = {Sensors (Basel, Switzerland)},
	volume       = 21,
	xurlx          = {https://api.semanticscholar.org/CorpusID:231908716}
}
@article{Dong2024ConMambaCA,
	title        = {ConMamba: CNN and SSM High-Performance Hybrid Network for Remote Sensing Change Detection},
	author       = {Zhiwei Dong and Genji Yuan and Zhen Hua and Jinjiang Li},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--15},
	xurlx          = {https://api.semanticscholar.org/CorpusID:273982248}
}
@article{Dong2024ISANetAI,
	title        = {ISANet: An Interactive Self-attention Network for Cropland Image Change Detection},
	author       = {Sijun Dong and Yanrui Chen and Fann Wu and Zhi Gao and Xiaoliang Meng},
	year         = 2024,
	journal      = {2024 IEEE 18th International Conference on Control \& Automation (ICCA)},
	pages        = {862--867},
	xurlx          = {https://api.semanticscholar.org/CorpusID:271463254}
}
@article{Dosovitskiy2020AnII,
	title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
	author       = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
	year         = 2020,
	journal      = {ArXiv},
	volume       = {abs/2010.11929},
	xurlx          = {https://api.semanticscholar.org/CorpusID:225039882}
}
@article{f_zhou_dual-granularity_2025,
	title        = {Dual-Granularity Feature Alignment for Change Detection in Remote Sensing Images},
	author       = {{F. Zhou} and {X. Zhang} and {H. Shuai} and {R. Hang} and {S. Zhu} and {T. Geng}},
	volume       = 18,
	pages        = {4487--4497},
	doi          = {10.1109/JSTARS.2025.3526795},
	issn         = {2151-1535},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	date         = 2025
}
@article{fang_changer_2022,
	title        = {Changer: Feature Interaction is What You Need for Change Detection},
	author       = {Fang, Sheng and Li, Kaiyu and Li, Zhe},
	volume       = 61,
	pages        = {1--11},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2022
}
@article{Fang2021SNUNetCDAD,
	title        = {SNUNet-CD: A Densely Connected Siamese Network for Change Detection of VHR Images},
	author       = {Sheng Fang and Kaiyu Li and Jinyuan Shao and Zhe Li},
	year         = 2021,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	volume       = 19,
	pages        = {1--5},
	xurlx          = {https://api.semanticscholar.org/CorpusID:233967703}
}
@article{feng_change_2023,
  title={Change Detection on Remote Sensing Images Using Dual-Branch Multilevel Intertemporal Network},
  author={Yuchao Feng and Jiawei Jiang and Honghui Xu and Jianwei Zheng},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2023},
  volume={61},
  pages={1-15},
  xurlx={https://api.semanticscholar.org/CorpusID:256526504}
}
@article{feng_ddam-net_2024,
	title        = {{DDAM}-Net: A Difference-Directed Multi-Scale Attention Mechanism Network for Cultivated Land Change Detection},
	author       = {Feng, Junbiao and Yu, Haikun and Lu, Xiaoping and Lv, Xiaoran and Zhou, Junli},
	volume       = 24,
	number       = 21,
	doi          = {10.3390/s24217040},
	issn         = {1424-8220},
	abstract     = {Declining cultivated land poses a serious threat to food security. However, existing Change Detection ({CD}) methods are insufficient for overcoming intra-class differences in cropland, and the accumulation of irrelevant features and loss of key features leads to poor detection results. To effectively identify changes in agricultural land, we propose a Difference-Directed Multi-scale Attention Mechanism Network ({DDAM}-Net). Specifically, we use a feature extraction module to effectively extract the cropland’s multi-scale features from dual-temporal images, and we introduce a Difference Enhancement Fusion Module ({DEFM}) and a Cross-scale Aggregation Module ({CAM}) to pass and fuse the multi-scale and difference features layer by layer. In addition, we introduce the Attention Refinement Module ({ARM}) to optimize the edge and detail features of changing objects. In the experiments, we evaluated the applicability of {DDAM}-Net on the {HN}-{CLCD} dataset for cropland {CD} and non-agricultural identification, with F1 and precision of 79.27\% and 80.70\%, respectively. In addition, generalization experiments using the publicly accessible {PX}-{CLCD} and {SET}-{CLCD} datasets revealed F1 and precision values of 95.12\% and 95.47\%, and 72.40\% and 77.59\%, respectively. The relevant comparative and ablation experiments suggested that {DDAM}-Net has greater performance and reliability in detecting cropland changes.},
	journaltitle = {Sensors},
	date         = 2024,
	keywords     = {attention mechanism, change detection, high-resolution remote-sensing images, non-agricultural change, self-built dataset}
}
@article{Feng2022ICIFNetIC,
	title        = {ICIF-Net: Intra-Scale Cross-Interaction and Inter-Scale Feature Fusion Network for Bitemporal Remote Sensing Images Change Detection},
	author       = {Yuchao Feng and Honghui Xu and Jiawei Jiang and Hao Liu and Jianwei Zheng},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--13},
	xurlx          = {https://api.semanticscholar.org/CorpusID:248252324}
}
@article{feng2023change,
	title        = {Change detection on remote sensing images using dual-branch multilevel intertemporal network},
	author       = {Feng, Yuchao and Jiang, Jiawei and Xu, Honghui and Zheng, Jianwei},
	year         = 2023,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	publisher    = {IEEE},
	volume       = 61,
	pages        = {1--15}
}
@article{Feng2025HybridMambaCDHM,
	title        = {Hybrid-MambaCD: Hybrid Mamba-CNN Network for Remote Sensing Image Change Detection With Region-Channel Attention Mechanism and Iterative Global-Local Feature Fusion},
	author       = {Yuxin Feng and Li Zhuo and Hui Zhang and Jiafeng Li},
	year         = 2025,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 63,
	pages        = {1--12},
	xurlx          = {https://api.semanticscholar.org/CorpusID:276707216}
}
@article{gao_adaptive_2025,
	title        = {Adaptive Frequency Enhancement Network for Remote Sensing Image Semantic Segmentation},
	author       = {Gao, Feng and Fu, Miao and Cao, Jingchao and Dong, Junyu and Du, Qian},
	pages        = {1--1},
	doi          = {10.1109/TGRS.2025.3558472},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2025,
	keywords     = {adaptive feature interaction, Adaptive systems, Convolutional neural networks, Fast Fourier transforms, Feature extraction, frequency domain features, Frequency modulation, Frequency-domain analysis, Land surface, remote sensing, Remote sensing, Semantic segmentation, spatial-frequency integration, Transformers}
}
@article{Girshick2013RichFH,
	title        = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
	author       = {Ross B. Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
	year         = 2013,
	journal      = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {580--587},
	xurlx          = {https://api.semanticscholar.org/CorpusID:215827080}
}
@article{gu2023fdff,
	title        = {FDFF-Net: A full-scale difference feature fusion network for change detection in high-resolution remote sensing images},
	author       = {Gu, Feng and Xiao, Pengfeng and Zhang, Xueliang and Li, Zhenshi and Muhtar, Dilxat},
	year         = 2023,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	publisher    = {IEEE},
	volume       = 17,
	pages        = {2161--2172}
}
@article{Gu2023MambaLS,
	title        = {Mamba: {{Linear-time}} Sequence Modeling with Selective State Spaces},
	author       = {Gu, Albert and Dao, Tri},
	year         = 2023,
	journal      = {ArXiv},
	volume       = {abs/2312.00752},
	xurlx          = {https://api.semanticscholar.org/CorpusID:265551773},
	date         = 2023,
	journaltitle = {ArXiv}
}
@article{h_ren_interactive_2025,
	title        = {Interactive and Supervised Dual-Mode Attention Network for Remote Sensing Image Change Detection},
	author       = {{H. Ren} and {M. Xia} and {L. Weng} and {H. Lin} and {J. Huang} and {K. Hu}},
	volume       = 63,
	pages        = {1--18},
	doi          = {10.1109/TGRS.2025.3540864},
	issn         = {1558-0644},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2025
}
@article{h_wei_spatio-temporal_2024,
	title        = {Spatio-Temporal Feature Fusion and Guide Aggregation Network for Remote Sensing Change Detection},
	author       = {{H. Wei} and {N. Wang} and {Y. Liu} and {P. Ma} and {D. Pang} and {X. Sui} and {Q. Chen}},
	volume       = 62,
	pages        = {1--16},
	doi          = {10.1109/TGRS.2024.3470314},
	issn         = {1558-0644},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2024
}
@inproceedings{h_zhang_context_2018,
	title        = {Context Encoding for Semantic Segmentation},
	author       = {{H. Zhang} and {K. Dana} and {J. Shi} and {Z. Zhang} and {X. Wang} and {A. Tyagi} and {A. Agrawal}},
	booktitle    = {2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages        = {7151--7160},
	doi          = {10.1109/CVPR.2018.00747},
	xurlx          = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2018.00747},
	note         = {Journal Abbreviation: 2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	abstract     = {Recent work has made significant progress in improving spatial resolution for pixelwise labeling with Fully Convolutional Network ({FCN}) framework by employing Dilated/Atrous convolution, utilizing multi-scale features and refining boundaries. In this paper, we explore the impact of global contextual information in semantic segmentation by introducing the Context Encoding Module, which captures the semantic context of scenes and selectively highlights class-dependent featuremaps. The proposed Context Encoding Module significantly improves semantic segmentation results with only marginal extra computation cost over {FCN}. Our approach has achieved new state-of-the-art results 51.7\% {mIoU} on {PASCAL}-Context, 85.9\% {mIoU} on {PASCAL} {VOC} 2012. Our single model achieves a final score of 0.5567 on {ADE}20K test set, which surpasses the winning entry of {COCO}-Place Challenge 2017. In addition, we also explore how the Context Encoding Module can improve the feature representation of relatively shallow networks for the image classification on {CIFAR}-10 dataset. Our 14 layer network has achieved an error rate of 3.45\%, which is comparable with state-of-the-art approaches with over 10Ã- more layers. The source code for the complete system are publicly available1.},
	eventtitle   = {2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	date         = {2018-06-18},
	keywords     = {Convolution, Encoding, Feature Extraction, Image Coding, Image Segmentation, Semantics, Training}
}
@article{han_change_2023,
  title={Change Guiding Network: Incorporating Change Prior to Guide Change Detection in Remote Sensing Imagery},
  author={Chengxi Han and Chen Wu and Haonan Guo and Meiqi Hu and Jiepan Li and Hongruixuan Chen},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year={2024},
  volume={16},
  pages={8395-8407},
  xurlx={https://api.semanticscholar.org/CorpusID:261410320}
}
@article{Han2024HANetAH,
  title={HANet: A Hierarchical Attention Network for Change Detection With Bitemporal Very-High-Resolution Remote Sensing Images},
  author={Chengxi Han and Chen Wu and Haonan Guo and Meiqi Hu and Hongruixuan Chen},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year={2024},
  volume={16},
  pages={3867-3878},
  xurlx={https://api.semanticscholar.org/CorpusID:257992434}
}
@article{Han2023HCGMNetAH,
	title        = {HCGMNet: A Hierarchical Change Guiding Map Network for Change Detection},
	author       = {Chengxi Han and Chen Wu and Bo Du},
	year         = 2023,
	journal      = {IGARSS 2023 - 2023 IEEE International Geoscience and Remote Sensing Symposium},
	pages        = {5511--5514},
	xurlx          = {https://api.semanticscholar.org/CorpusID:257050289}
}
@article{Han2025HFIFNetHF,
	title        = {HFIFNet: Hierarchical Feature Interaction Network With Multiscale Fusion for Change Detection},
	author       = {Mingzhi Han and Tao Xu and Qingjie Liu and Xiaohui Yang and Jing Wang and Jiaqi Kong},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 18,
	pages        = {4318--4330},
	xurlx          = {https://api.semanticscholar.org/CorpusID:275486271}
}
@misc{he_masked_2021,
	title        = {Masked Autoencoders Are Scalable Vision Learners},
	author       = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Dollár, Piotr and Girshick, Ross},
	publisher    = {{arXiv}},
	number       = {{arXiv}:2111.06377},
	xurlx          = {http://arxiv.org/abs/2111.06377},
	xurlxdate      = {2023-10-23},
	abstract     = {This paper shows that masked autoencoders ({MAE}) are scalable self-supervised learners for computer vision. Our {MAE} approach is simple: we mask random patches of the input image and reconstruct the missing pixels. It is based on two core designs. First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens. Second, we ﬁnd that masking a high proportion of the input image, e.g., 75\%, yields a nontrivial and meaningful self-supervisory task. Coupling these two designs enables us to train large models efﬁciently and effectively: we accelerate training (by 3× or more) and improve accuracy. Our scalable approach allows for learning high-capacity models that generalize well: e.g., a vanilla {ViT}-Huge model achieves the best accuracy (87.8\%) among methods that use only {ImageNet}-1K data. Transfer performance in downstream tasks outperforms supervised pretraining and shows promising scaling behavior.},
	date         = {2021-12-19},
	langid       = {english},
	eprinttype   = {arxiv},
	eprint       = {2111.06377 [cs]},
	keywords     = {Computer Science - Computer Vision and Pattern Recognition},
	file         = {He 等 - 2021 - Masked Autoencoders Are Scalable Vision Learners.pdf:files/56/He 等 - 2021 - Masked Autoencoders Are Scalable Vision Learners.pdf:application/pdf}
}
@article{He2019MomentumCF,
	title        = {Momentum Contrast for Unsupervised Visual Representation Learning},
	author       = {Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross B. Girshick},
	year         = 2019,
	journal      = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {9726--9735},
	xurlx          = {https://api.semanticscholar.org/CorpusID:207930212}
}
@article{Hu2017SqueezeandExcitationN,
	title        = {Squeeze-and-Excitation Networks},
	author       = {Jie Hu and Li Shen and Samuel Albanie and Gang Sun and Enhua Wu},
	year         = 2017,
	journal      = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {7132--7141},
	xurlx          = {https://api.semanticscholar.org/CorpusID:140309863}
}
@article{Huang_RemoteSens_2023_v15_p3972,
	title        = {{Siam-EMNet: A Siamese EfficientNet{\textendash}MANet Network for Building Change Detection in Very High Resolution Images}},
	author       = {Liang Huang and Qiuyuan Tian and Bo-Hui Tang and Weipeng Le and Min Wang and Xianguang Ma},
	year         = 2023,
	journal      = {Remote. Sens.},
	volume       = 15,
	number       = 16,
	pages        = 3972,
	doi          = {10.3390/rs15163972},
	abstract     = {As well as very high resolution (VHR) remote sensing technology and deep learning, methods for detecting changes in buildings have made great progress. Despite this, there are still some problems with the incomplete detection of change regions and rough edges. To this end, a change detection network for building VHR remote sensing images based on Siamese EfficientNet B4-MANet (Siam-EMNet) is proposed. First, a bi-branches pretrained EfficientNet B4 encoder structure is constructed to enhance the performance of feature extraction and the rich shallow and deep information is obtained; then, the semantic information of the building is input into the MANet decoder integrated by the dual attention mechanism through the skip connection. The position-wise attention block (PAB) and multi-scale fusion attention block (MFAB) capture spatial relationships between pixels in the global view and channel relationships between layers. The integration of dual attention mechanisms ensures that the building contour is fully detected. The proposed method was evaluated on the LEVIR-CD dataset, and its precision, recall, accuracy, and F1-score were 92.00{\%}, 88.51{\%}, 95.71{\%}, and 90.21{\%}, respectively, which represented the best overall performance compared to the BIT, CDNet, DSIFN, L-Unet, P2V-CD, and SNUNet methods. Verification of the efficacy of the suggested approach was then conducted.}
}
@article{Huang2025MSAMS,
	title        = {MSA: Mamba Semantic Alignment Networks for Remote Sensing Change Detection},
	author       = {Zhenyang Huang and Peng Duan and Genji Yuan and Jinjiang Li},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 18,
	pages        = {10625--10639},
	xurlx          = {https://api.semanticscholar.org/CorpusID:277538947}
}
@article{j_chen_sganet_2025,
	title        = {{SGANet}: A Siamese Geometry-Aware Network for Remote Sensing Change Detection},
	author       = {{J. Chen} and {S. Dong} and {X. Meng}},
	volume       = 18,
	pages        = {6232--6248},
	doi          = {10.1109/JSTARS.2025.3539733},
	issn         = {2151-1535},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	date         = 2025
}
@article{j_li_trsanet_2024,
	title        = {{TRSANet}: A Remote Sensing Deep Learning Model for Water Body Change Detection Based on Time-Reversal Semantic Asymmetry},
	author       = {{J. Li} and {C. Jin} and {Y. Shen} and {W. Ye}},
	volume       = 62,
	pages        = {1--13},
	doi          = {10.1109/TGRS.2024.3458951},
	issn         = {1558-0644},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2024
}
@article{Ji2019FullyCN,
	title        = {Fully Convolutional Networks for Multisource Building Extraction From an Open Aerial and Satellite Imagery Data Set},
	author       = {Shunping Ji and Shiqing Wei and Meng Lu},
	year         = 2019,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 57,
	pages        = {574--586},
	xurlx          = {https://api.semanticscholar.org/CorpusID:57190346}
}
@article{Jiang2022JointVL,
	title        = {Joint Variation Learning of Fusion and Difference Features for Change Detection in Remote Sensing Images},
	author       = {Kaixuan Jiang and Wenhua Zhang and Jia Liu and F. Liu and Liang Xiao},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--18},
	xurlx          = {https://api.semanticscholar.org/CorpusID:254343852}
}
@article{Julka2023KnowledgeDW,
	title        = {Knowledge distillation with Segment Anything (SAM) model for Planetary Geological Mapping},
	author       = {Sahib Julka and Michael Granitzer},
	year         = 2023,
	journal      = {ArXiv},
	volume       = {abs/2305.07586},
	xurlx          = {https://api.semanticscholar.org/CorpusID:258676387}
}
@article{Khan2023ARTriViTAF,
	title        = {ARTriViT: Automatic Face Recognition System Using ViT-Based Siamese Neural Networks with a Triplet Loss},
	author       = {Mustaqeem Khan and Muhammad Saeed and Abdulmotaleb El Saddik and Wail Gueaieb},
	year         = 2023,
	journal      = {2023 IEEE 32nd International Symposium on Industrial Electronics (ISIE)},
	pages        = {1--6},
	xurlx          = {https://api.semanticscholar.org/CorpusID:261435659}
}
@article{Khanna2023DiffusionSatAG,
	title        = {DiffusionSat: A Generative Foundation Model for Satellite Imagery},
	author       = {Samar Khanna and Patrick Liu and Linqi Zhou and Chenlin Meng and Robin Rombach and Marshall Burke and David B. Lobell and Stefano Ermon},
	year         = 2023,
	journal      = {ArXiv},
	volume       = {abs/2312.03606},
	xurlx          = {https://api.semanticscholar.org/CorpusID:265732275}
}
@inproceedings{Kim2018BilinearAN,
	title        = {Bilinear Attention Networks},
	author       = {Jin-Hwa Kim and Jaehyun Jun and Byoung-Tak Zhang},
	year         = 2018,
	booktitle    = {Neural Information Processing Systems},
	xurlx          = {https://api.semanticscholar.org/CorpusID:29150617}
}
@article{Kirillov2023SegmentA,
	title        = {Segment Anything},
	author       = {Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chlo{\'e} Rolland and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C. Berg and Wan-Yen Lo and Piotr Doll{\'a}r and Ross B. Girshick},
	year         = 2023,
	journal      = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {3992--4003},
	xurlx          = {https://api.semanticscholar.org/CorpusID:257952310}
}
@inproceedings{Koch2015SiameseNN,
	title        = {Siamese Neural Networks for One-Shot Image Recognition},
	author       = {Gregory R. Koch},
	year         = 2015,
	xurlx          = {https://api.semanticscholar.org/CorpusID:13874643}
}
@article{lebedev_change_2018,
	title        = {{CHANGE} {DETECTION} {IN} {REMOTE} {SENSING} {IMAGES} {USING} {CONDITIONAL} {ADVERSARIAL} {NETWORKS}},
	author       = {Lebedev, M. A. and Vizilter, Y. V. and Vygolov, O. V. and Knyaz, V. A. and Rubis, A. Y.},
	volume       = {{XLII}-2},
	pages        = {565--571},
	doi          = {10.5194/isprs-archives-XLII-2-565-2018},
	issn         = {2194-9034},
	xurlx          = {https://isprs-archives.copernicus.org/articles/XLII-2/565/2018/},
	xurlxdate      = {2023-10-23},
	abstract     = {We present a method for change detection in images using Conditional Adversarial Network approach. The original network architecture based on pix2pix is proposed and evaluated for difference map creation. The paper address three types of experiments: change detection in synthetic images without objects relative shift, change detection in synthetic images with small relative shift of objects, and change detection in real season-varying remote sensing images.},
	journaltitle = {Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.},
	date         = {2018-05-30},
	langid       = {english},
	file         = {Lebedev 等 - 2018 - CHANGE DETECTION IN REMOTE SENSING IMAGES USING CO.pdf:files/68/Lebedev 等 - 2018 - CHANGE DETECTION IN REMOTE SENSING IMAGES USING CO.pdf:application/pdf}
}
@article{Lebedev2018CHANGEDI,
	title        = {CHANGE DETECTION IN REMOTE SENSING IMAGES USING CONDITIONAL ADVERSARIAL NETWORKS},
	author       = {Maxim Lebedev and Yu. V. Vizilter and Oleg Vygolov and Vladimir Alexandrovich Knyaz and A. Yu. Rubis},
	year         = 2018,
	journal      = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	xurlx          = {https://api.semanticscholar.org/CorpusID:57660599}
}
@article{Lee2021LocalSS,
	title        = {Local Similarity Siamese Network for Urban Land Change Detection on Remote Sensing Images},
	author       = {Haeyun Lee and Kyungsu Lee and Jun Hee Kim and Younghwan Na and Juhum Park and Jihwan P. Choi and Jae Youn Hwang},
	year         = 2021,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 14,
	pages        = {4139--4149},
	xurlx          = {https://api.semanticscholar.org/CorpusID:233434317}
}
@article{Lei2022BoundaryEC,
	title        = {Boundary Extraction Constrained Siamese Network for Remote Sensing Image Change Detection},
	author       = {Jie Lei and Yijie Gu and Weiying Xie and Yunsong Li and Qian Du},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--13},
	xurlx          = {https://api.semanticscholar.org/CorpusID:248056211}
}
@article{li_a2-fpn_2022,
	title        = {A2-{FPN} for semantic segmentation of fine-resolution remotely sensed images},
	author       = {Li, Rui and Wang, Libo and Zhang, Ce and Duan, Chenxi and Zheng, Shunyi},
	volume       = 43,
	number       = 3,
	pages        = {1131--1155},
	doi          = {10.1080/01431161.2022.2030071},
	note         = {Publisher: Taylor \& Francis},
	journaltitle = {International Journal of Remote Sensing},
	date         = 2022
}
@article{li_cmcd_2025,
	title        = {{CMCD}: A Consistency Model-based Change Detection Method for Remote Sensing Images},
	author       = {Li, Xiongjie and Xie, Weiying and Zhang, Jiaqing and Li, Yunsong},
	pages        = {1--14},
	doi          = {10.1109/JSTARS.2025.3554659},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	date         = 2025,
	keywords     = {Change detection, Computational modeling, consistency mode, Convolutional neural networks, Data models, Diffusion models, diffusion-based model, Feature extraction, Noise, Remote sensing, Semantics, Training, Transformers}
}
@article{li_densely_2022,
	title        = {A Densely Attentive Refinement Network for Change Detection Based on Very-High-Resolution Bitemporal Remote Sensing Images},
	author       = {Li, Ziming and Yan, Chenxi and Sun, Ying and Xin, Qinchuan},
	volume       = 60,
	pages        = {1--18},
	doi          = {10.1109/TGRS.2022.3159544},
	issn         = {0196-2892, 1558-0644},
	xurlx          = {https://ieeexplore.ieee.org/document/9734050/},
	xurlxdate      = {2023-10-23},
	abstract     = {Detecting changes using bitemporal remote sensing imagery is vital to understand the dynamics of the land surface. Existing change detection models based on deep learning suffer from the problem of scale variation and pseudochange due to their insufﬁcient multilevel aggregation and inadequate capability of feature representation, which limits the accuracy. This study proposes a densely attentive reﬁnement network ({DARNet}) to improve change detection on bitemporal very-high-resolution remote sensing images. {DARNet} is based on the U-shape encoder–decoder architecture with the Siamese network as a feature extractor. The dense skip connection module ({DSCM}) is employed between the decoder and the encoder to aggregate multilevel feature maps. The hybrid attention module ({HAM}) is integrated to exploit contextual information and generate discriminative features. The recurrent reﬁnement module ({RRM}) is exploited to progressively reﬁne the predicted change maps during the decoding process. Experiments on testing the model performance were conducted on three benchmark datasets: the season-varying change detection ({SVCD}) dataset, the Sun Yat-sen University change detection ({SYSU}-{CD}) dataset, and the Learning Vision and Remote Sensing Laboratory building change detection ({LEVIR}-{CD}) dataset. The experimental results demonstrate that {DARNet} outperforms state-of-the-art models with kappa of 96.58\%, 75.35\%, and 90.69\% for the {SVCD}, {SYSU}-{CD}, and {LEVIR}-{CD} datasets, respectively.},
	journaltitle = {{IEEE} Trans. Geosci. Remote Sensing},
	date         = 2022,
	langid       = {english},
	file         = {Li 等 - 2022 - A Densely Attentive Refinement Network for Change .pdf:files/80/Li 等 - 2022 - A Densely Attentive Refinement Network for Change .pdf:application/pdf;Li 等 - 2022 - A Densely Attentive Refinement Network for Change .pdf:files/105/Li 等 - 2022 - A Densely Attentive Refinement Network for Change .pdf:application/pdf}
}
@article{li_dual_2025,
	title        = {Dual Fine-Grained network with frequency Transformer for change detection on remote sensing images},
	author       = {Li, Zhen and Zhang, Zhenxin and Li, Mengmeng and Zhang, Liqiang and Peng, Xueli and He, Rixing and Shi, Leidong},
	volume       = 136,
	pages        = 104393,
	doi          = {10.1016/j.jag.2025.104393},
	issn         = {1569-8432},
	xurlx          = {https://www.sciencedirect.com/science/article/pii/S1569843225000408},
	abstract     = {Change detection is a fundamental yet challenging task in remote sensing, crucial for monitoring urban expansion, land use changes, and environmental dynamics. However, compared with common color images, objects in remote sensing images exhibit minimal interclass variation and significant intraclass variation in the spectral dimension, with obvious scale inconsistency in the spatial dimension. Change detection complexity presents significant challenges, including differentiating similar objects, accounting for scale variations, and identifying pseudo changes. This research introduces a dual fine-grained network with a frequency Transformer (named as {FTransDF}-Net) to address the above issues. Specifically, for small-scale and approximate spectral ground objects, the network employs an encoder-decoder architecture consisting of dual fine-grained gated ({DFG}) modules. This enables the extraction and fusion of fine-grained level information in dual dimensions of features, facilitating a comprehensive analysis of their differences and correlations. As a result, a dynamic fusion representation of salient information is achieved. Additionally, we develop a lightweight frequency transformer ({LFT}) with minimal parameters for detecting large-scale ground objects that undergo significant changes over time. This is achieved by incorporating a frequency attention ({FA}) module, which utilizes Fourier transform to model long-range dependencies and combines global adaptive attentive features with multi-level fine-grained features. Our comparative experiments across four publicly available datasets demonstrate that {FTransDF}-Net reaches advanced results. Importantly, it outperforms the leading comparison method by 1.23\% and 2.46\% regarding {IoU} metrics concerning {CDD} and {DSIFN}, respectively. Furthermore, efficacy for each module is substantiated through ablation experiments. The code is accessible on https://github.com/{LeeThrzz}/{FTrans}-{DF}-Net.},
	journaltitle = {International Journal of Applied Earth Observation and Geoinformation},
	date         = {2025-02-01},
	keywords     = {Change detection, Dual fine-grained, Frequency transformer, Remote sensing}
}
@article{li_multiattention_2022,
	title        = {Multiattention Network for Semantic Segmentation of Fine-Resolution Remote Sensing Images},
	author       = {Li, Rui and Zheng, Shunyi and Zhang, Ce and Duan, Chenxi and Su, Jianlin and Wang, Libo and Atkinson, Peter M.},
	volume       = 60,
	pages        = {1--13},
	doi          = {10.1109/TGRS.2021.3093977},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2022,
	keywords     = {Attention mechanism, Complexity theory, Feature extraction, fine-resolution remote sensing images, Image segmentation, Kernel, Remote sensing, semantic segmentation, Semantics, Task analysis}
}
@article{li_overcoming_2025,
	title        = {Overcoming the uncertainty challenges in detecting building changes from remote sensing images},
	author       = {Li, Jiepan and He, Wei and Li, Zhuohong and Guo, Yujun and Zhang, Hongyan},
	volume       = 220,
	pages        = {1--17},
	doi          = {10.1016/j.isprsjprs.2024.11.017},
	issn         = {0924-2716},
	xurlx          = {https://www.sciencedirect.com/science/article/pii/S092427162400426X},
	abstract     = {Detecting building changes with multi-temporal remote sensing ({RS}) imagery at a very high resolution can help us understand urbanization and human activities, making informed decisions in urban planning, resource allocation, and infrastructure development. However, existing methods for building change detection ({BCD}) generally overlook critical uncertainty phenomena presented in {RS} imagery. Specifically, these uncertainties arise from two main sources: First, current building change detection datasets are designed primarily to detect changes in buildings, while changes in other land-cover classes are often classified as an unchanged background. Because of the manual labeling process, background elements that resemble buildings, such as roads and bridges, are at significant risk of being misclassified as building changes, introducing aleatoric uncertainty at the data level. Second, changes in parts of buildings that affect appearance, texture, or style without altering their semantic meaning, known as pseudo-changes, along with the imbalance between changed and unchanged samples, together lead to epistemic uncertainty at the model level. To address these challenges, we present an Uncertainty-Aware {BCD} ({UA}-{BCD}) framework. In detail, we employ a Siamese pyramid vision transformer to extract multi-level features from bi-temporal images, which are then decoded via a general decoder to obtain a coarse change map with inherent uncertainty. Subsequently, we introduce the aleatoric uncertainty estimation module to estimate the aleatoric uncertainty and embed it into the feature space. Then, a knowledge-guided feature enhancement module is developed to leverage the knowledge encoded in the coarse map to enhance the multi-level features and generate a refined change map. Finally, we propose an epistemic uncertainty estimator that takes the bi-temporal images and the refined change map as input and outputs an estimate of epistemic uncertainty. This estimation is supervised by the entropy calculated from the refined map, ensuring that the {UA}-{BCD} framework can produce a change map with lower epistemic uncertainty. To comprehensively validate the efficacy of the {UA}-{BCD} framework, we adopt a dual-perspective verification approach. Extensive experiments on five public building change datasets demonstrate the significant advantages of the proposed method over current state-of-the-art methods. Additionally, an application in Dongxihu District, Wuhan, China, confirms the outstanding performance of the proposed method in large-scale {BCD}. The source code of the project is available at https://github.com/Henryjiepanli/{UA}-{BCD}.},
	journaltitle = {{ISPRS} Journal of Photogrammetry and Remote Sensing},
	date         = {2025-02-01},
	keywords     = {Remote sensing, Building change detection, Building change detection mapping, Uncertainty-related theory}
}
@article{li_stade-cdnet_2024,
	title        = {{STADE}-{CDNet}: Spatial–Temporal Attention With Difference Enhancement-Based Network for Remote Sensing Image Change Detection},
	author       = {Li, Zhi and Cao, Siying and Deng, Jiakun and Wu, Fengyi and Wang, Ruilan and Luo, Junhai and Peng, Zhenming},
	volume       = 62,
	pages        = {1--17},
	doi          = {10.1109/TGRS.2024.3367948},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2024,
	keywords     = {Remote sensing, Deep learning, Feature extraction, Semantics, Transformers, Data mining, transformer, Change detection ({CD}) difference enhancement, Memory modules, multitemporal image pairs, temporal memory}
}
@article{Li2019ExpectationMaximizationAN,
	title        = {Expectation-Maximization Attention Networks for Semantic Segmentation},
	author       = {Xia Li and Zhisheng Zhong and Jianlong Wu and Yibo Yang and Zhouchen Lin and Hong Liu},
	year         = 2019,
	journal      = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {9166--9175},
	xurlx          = {https://api.semanticscholar.org/CorpusID:199001043}
}
@article{Li2021GlobalAL,
	title        = {Global and Local Contrastive Self-Supervised Learning for Semantic Segmentation of HR Remote Sensing Images},
	author       = {Haifeng Li and Yi Li and Guo Zhang and Ruoyun Liu and Haozhe Huang and Qing Zhu and Chao Tao},
	year         = 2021,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--14},
	xurlx          = {https://api.semanticscholar.org/CorpusID:246417907}
}
@article{Li2022MCANetAJ,
	title        = {MCANet: A joint semantic segmentation framework of optical and SAR images for land use classification},
	author       = {Xue Li and Guo Zhang and Hao Cui and Shasha Hou and Shunyao Wang and Xin Li and Yujia Chen and Zhijiang Li and Li Zhang},
	year         = 2022,
	journal      = {Int. J. Appl. Earth Obs. Geoinformation},
	volume       = 106,
	pages        = 102638,
	xurlx          = {https://api.semanticscholar.org/CorpusID:245610946}
}
@article{Li2022SDMNetAD,
	title        = {SDMNet: A Deep-Supervised Dual Discriminative Metric Network for Change Detection in High-Resolution Remote Sensing Images},
	author       = {Xi Li and Li-Li Yan and Yi Zhang and Nan Mo},
	year         = 2022,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	volume       = 19,
	pages        = {1--5},
	xurlx          = {https://api.semanticscholar.org/CorpusID:253271216}
}
@article{Li2022TransUNetCDAH,
	title        = {TransUNetCD: A Hybrid Transformer Network for Change Detection in Optical Remote-Sensing Images},
	author       = {Qingyang Li and Ruofei Zhong and Xin Du and Yuying Du},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--19},
	xurlx          = {https://api.semanticscholar.org/CorpusID:248348338}
}
@article{Li2023LargeSK,
	title        = {Large Selective Kernel Network for Remote Sensing Object Detection},
	author       = {Yuxuan Li and Qibin Hou and Zhaohui Zheng and Mingmei Cheng and Jian Yang and Xiang Li},
	year         = 2023,
	journal      = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {16748--16759},
	xurlx          = {https://api.semanticscholar.org/CorpusID:257557163}
}
@article{Li2023MDFENetAM,
	title        = {MDFENet: A Multiscale Difference Feature Enhancement Network for Remote Sensing Change Detection},
	author       = {Hao Li and Xiaoyong Liu and Huihui Li and Ziyang Dong and Xiang Xiao},
	year         = 2023,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 16,
	pages        = {3104--3115},
	xurlx          = {https://api.semanticscholar.org/CorpusID:257683448}
}
@article{Liang2022LocalGlobalCA,
	title        = {Local-Global Context Aware Transformer for Language-Guided Video Segmentation},
	author       = {Chen Liang and Wenguan Wang and Tianfei Zhou and Jiaxu Miao and Yawei Luo and Yi Yang},
	year         = 2022,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume       = 45,
	pages        = {10055--10069},
	xurlx          = {https://api.semanticscholar.org/CorpusID:247593860}
}
@inproceedings{lin_feature_2017,
	title        = {Feature Pyramid Networks for Object Detection},
	author       = {Lin, Tsung-Yi and Dollar, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
	booktitle    = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	location     = {Honolulu, {HI}},
	publisher    = {{IEEE}},
	pages        = {936--944},
	doi          = {10.1109/CVPR.2017.106},
	isbn         = {978-1-5386-0457-1},
	xurlx          = {http://ieeexplore.ieee.org/document/8099589/},
	xurlxdate      = {2023-10-23},
	abstract     = {Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But recent deep learning object detectors have avoided pyramid representations, in part because they are compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A topdown architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network ({FPN}), shows signiﬁcant improvement as a generic feature extractor in several applications. Using {FPN} in a basic Faster R-{CNN} system, our method achieves state-of-the-art singlemodel results on the {COCO} detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the {COCO} 2016 challenge winners. In addition, our method can run at 5 {FPS} on a {GPU} and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.},
	eventtitle   = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	date         = {2017-07},
	langid       = {english},
	file         = {Lin 等 - 2017 - Feature Pyramid Networks for Object Detection.pdf:files/108/Lin 等 - 2017 - Feature Pyramid Networks for Object Detection.pdf:application/pdf}
}
@article{lin_transition_2023,
	title        = {Transition Is a Process: Pair-to-Video Change Detection Networks for Very High Resolution Remote Sensing Images},
	shorttitle   = {Transition Is a Process},
	author       = {Lin, Manhui and Yang, Guangyi and Zhang, Hongyan},
	volume       = 32,
	pages        = {57--71},
	doi          = {10.1109/TIP.2022.3226418},
	issn         = {1057-7149, 1941-0042},
	xurlx          = {https://ieeexplore.ieee.org/document/9975266/},
	xurlxdate      = {2023-10-23},
	abstract     = {As an important yet challenging task in Earth observation, change detection ({CD}) is undergoing a technological revolution, given the broadening application of deep learning. Nevertheless, existing deep learning-based {CD} methods still suffer from two salient issues: 1) incomplete temporal modeling, and 2) space-time coupling. In view of these issues, we propose a more explicit and sophisticated modeling of time and accordingly establish a pair-to-video change detection (P2V-{CD}) framework. First, a pseudo transition video that carries rich temporal information is constructed from the input image pair, interpreting {CD} as a problem of video understanding. Then, two decoupled encoders are utilized to spatially and temporally recognize the type of transition, and the encoders are laterally connected for mutual promotion. Furthermore, the deep supervision technique is applied to accelerate the model training. We illustrate experimentally that the P2V-{CD} method compares favorably to other state-of-the-art {CD} approaches in terms of both the visual effect and the evaluation metrics, with a moderate model size and relatively lower computational overhead. Extensive feature map visualization experiments demonstrate how our method works beyond making contrasts between bi-temporal images. Source code is available at https://github.com/Bobholamovic/{CDLab}.},
	journaltitle = {{IEEE} Trans. on Image Process.},
	date         = 2023,
	langid       = {english},
	file         = {Lin 等 - 2023 - Transition Is a Process Pair-to-Video Change Dete.pdf:files/106/Lin 等 - 2023 - Transition Is a Process Pair-to-Video Change Dete.pdf:application/pdf}
}
@article{Lin2024DiFormerAD,
	title        = {DiFormer: A Difference Transformer Network for Remote Sensing Change Detection},
	author       = {Hui Lin and Renlong Hang and Shan Wang and Qingshan Liu},
	year         = 2024,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	volume       = 21,
	pages        = {1--5},
	xurlx          = {https://api.semanticscholar.org/CorpusID:267330866}
}
@article{Ling2022IRAMRSNetAN,
	title        = {IRA-MRSNet: A Network Model for Change Detection in High-Resolution Remote Sensing Images},
	author       = {Jie Ling and Lei Hu and Lan Cheng and Minghui Chen and Xin Yang},
	year         = 2022,
	journal      = {Remote. Sens.},
	volume       = 14,
	pages        = 5598,
	xurlx          = {https://api.semanticscholar.org/CorpusID:253410211}
}
@article{liu_cwmamba_2025,
	title        = {{CWmamba}: Leveraging {CNN}-Mamba Fusion for Enhanced Change Detection in Remote Sensing Images},
	author       = {Liu, Yingchao and Cheng, Guangliang and Sun, Qihang and Tian, Chunpeng and Wang, Lukun},
	pages        = {1--1},
	doi          = {10.1109/LGRS.2025.3548145},
	journaltitle = {{IEEE} Geoscience and Remote Sensing Letters},
	date         = 2025,
	keywords     = {Remote sensing, Computational modeling, Convolutional neural networks, Feature extraction, Training, Transformers, Data mining, Computer architecture, Decoding, Mamba, Accuracy, Feature Extraction, Remote sensing change detection}
}
@article{liu_swin_2021-5,
	title        = {Swin Transformer V2: Scaling Up Capacity and Resolution},
	author       = {Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and Wei, Furu and Guo, Baining},
	pages        = {11999--12009},
	journaltitle = {2022 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	date         = 2021
}
@article{Liu2018DeepLF,
	title        = {Deep Learning for Generic Object Detection: A Survey},
	author       = {Li Liu and Wanli Ouyang and Xiaogang Wang and Paul W. Fieguth and Jie Chen and Xinwang Liu and Matti Pietik{\"a}inen},
	year         = 2018,
	journal      = {International Journal of Computer Vision},
	volume       = 128,
	pages        = {261--318},
	xurlx          = {https://api.semanticscholar.org/CorpusID:52177403}
}
@article{Liu2019BuildingCD,
	title        = {Building Change Detection for Remote Sensing Images Using a Dual-Task Constrained Deep Siamese Convolutional Network Model},
	author       = {Yi Liu and Chao Pang and Zongqian Zhan and Xiaomeng Zhang and Xue Yang},
	year         = 2019,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	volume       = 18,
	pages        = {811--815},
	xurlx          = {https://api.semanticscholar.org/CorpusID:202583748}
}
@article{Liu2021SwinTH,
	title        = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
	author       = {Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
	year         = 2021,
	journal      = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {9992--10002},
	xurlx          = {https://api.semanticscholar.org/CorpusID:232352874}
}
@article{Liu2022ACF,
	title        = {A ConvNet for the 2020s},
	author       = {Zhuang Liu and Hanzi Mao and Chaozheng Wu and Christoph Feichtenhofer and Trevor Darrell and Saining Xie},
	year         = 2022,
	journal      = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {11966--11976},
	xurlx          = {https://api.semanticscholar.org/CorpusID:245837420}
}
@article{Liu2022ACN,
	title        = {A CNN-Transformer Network With Multiscale Context Aggregation for Fine-Grained Cropland Change Detection},
	author       = {Mengxi Liu and Zhuoqun Chai and Haojun Deng and Rong Liu},
	year         = 2022,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 15,
	pages        = {4297--4306},
	xurlx          = {https://api.semanticscholar.org/CorpusID:249030261}
}
@article{Liu2022APM,
	title        = {A Probabilistic Model Based on Bipartite Convolutional Neural Network for Unsupervised Change Detection},
	author       = {Jia Liu and Wenhua Zhang and F. Liu and Liang Xiao},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--14},
	xurlx          = {https://api.semanticscholar.org/CorpusID:235841501}
}
@article{Liu2022BuildingCD,
	title        = {Building Change Detection for VHR Remote Sensing Images via Local–Global Pyramid Network and Cross-Task Transfer Learning Strategy},
	author       = {Tongfei Liu and Maoguo Gong and Di Lu and Qingfu Zhang and Hanhong Zheng and Fenlong Jiang and Mingyang Zhang},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--17},
	xurlx          = {https://api.semanticscholar.org/CorpusID:244670797}
}
@article{Liu2022RemoteSI,
	title        = {Remote Sensing Image Change Captioning With Dual-Branch Transformers: A New Method and a Large Scale Dataset},
	author       = {Chenyang Liu and Rui Zhao and Hao Chen and Zhengxia Zou and Zhen Xia Shi},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--20},
	xurlx          = {https://api.semanticscholar.org/CorpusID:253353490}
}
@article{Liu2023AnAM,
	title        = {An attention-based multiscale transformer network for remote sensing image change detection},
	author       = {Wei Liu and Yi-Yao Lin and Weijia Liu and Yongtao Yu and Jonathan Li},
	year         = 2023,
	journal      = {ISPRS Journal of Photogrammetry and Remote Sensing},
	xurlx          = {https://api.semanticscholar.org/CorpusID:259931492}
}
@inproceedings{Liu2023GroundingDM,
	title        = {Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection},
	author       = {Shilong Liu and Zhaoyang Zeng and Tianhe Ren and Feng Li and Hao Zhang and Jie Yang and Chun-yue Li and Jianwei Yang and Hang Su and Jun-Juan Zhu and Lei Zhang},
	year         = 2023,
	booktitle    = {European Conference on Computer Vision},
	xurlx          = {https://api.semanticscholar.org/CorpusID:257427307}
}
@article{Liu2024AMN,
	title        = {A Memory-Guided Network and a Novel Dataset for Cropland Semantic Change Detection},
	author       = {Mengxi Liu and Simin Lin and Yutong Zhong and Qian Shi and Jiaqi Li},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--13},
	xurlx          = {https://api.semanticscholar.org/CorpusID:270888645}
}
@article{Liu2024CandidateAwareAC,
	title        = {Candidate-Aware and Change-Guided Learning for Remote Sensing Change Detection},
	author       = {Fang Liu and Yangguang Liu and Jia Liu and Xu Tang and Liang Xiao},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--19},
	xurlx          = {https://api.semanticscholar.org/CorpusID:269827638}
}
@article{Liu2024ExploringTC,
	title        = {Exploring the Cross-Temporal Interaction: Feature Exchange and Enhancement for Remote Sensing Change Detection},
	author       = {Yikun Liu and Kuikui Wang and Mingsong Li and Yuwen Huang and Gongping Yang},
	year         = 2024,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 17,
	pages        = {11761--11776},
	xurlx          = {https://api.semanticscholar.org/CorpusID:270496888}
}
@article{Liu2024IterativeMD,
	title        = {Iterative Mamba Diffusion Change-Detection Model for Remote Sensing},
	author       = {Feixiang Liu and Yihan Wen and Jiayi Sun and Peipei Zhu and Liang Mao and Guanchong Niu and Jie Li},
	year         = 2024,
	journal      = {Remote. Sens.},
	volume       = 16,
	pages        = 3651,
	xurlx          = {https://api.semanticscholar.org/CorpusID:273006658}
}
@inproceedings{Lou2024ZeroshotST,
	title        = {Zero-shot surgical tool segmentation in monocular video using Segment Anything Model 2},
	author       = {Ange Lou and Yamin Li and Yike Zhang and Robert F Labadie and Jack H. Noble},
	year         = 2024,
	booktitle    = {Medical Imaging},
	xurlx          = {https://api.semanticscholar.org/CorpusID:271710346}
}
@article{lu_cross_2024,
	title        = {Cross attention is all you need: relational remote sensing change detection with transformer},
	author       = {Kaixuan Lu and Xiao Huang and Ruiheng Xia and Pan Zhang and Junping Shen},
	year         = 2024,
	journal      = {GIScience \& Remote Sensing},
	volume       = 61,
	xurlx          = {https://api.semanticscholar.org/CorpusID:271326551}
}
@inproceedings{Lu2019ViLBERTPT,
	title        = {ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},
	author       = {Jiasen Lu and Dhruv Batra and Devi Parikh and Stefan Lee},
	year         = 2019,
	booktitle    = {Neural Information Processing Systems},
	xurlx          = {https://api.semanticscholar.org/CorpusID:199453025}
}
@article{Lu2022RCDTRR,
	title        = {RCDT: Relational Remote Sensing Change Detection with Transformer},
	author       = {Kaixuan Lu and Xiao Huang},
	year         = 2022,
	journal      = {ArXiv},
	volume       = {abs/2212.04869},
	xurlx          = {https://api.semanticscholar.org/CorpusID:254535834}
}
@article{lv_land_2022,
	title        = {Land Cover Change Detection With Heterogeneous Remote Sensing Images: Review, Progress, and Perspective},
	author       = {Lv, {ZhiYong} and Huang, {HaiTao} and Li, Xinghua and Zhao, {MingHua} and Benediktsson, Jón Atli and Sun, {WeiWei} and Falco, Nicola},
	volume       = 110,
	number       = 12,
	pages        = {1976--1991},
	doi          = {10.1109/JPROC.2022.3219376},
	journaltitle = {Proceedings of the {IEEE}},
	date         = 2022,
	keywords     = {Remote sensing, Adaptive optics, Cross-modal change detection, cross-sensor change detection, different resolution change detection, Earthquakes, Heterogeneous networks, heterogeneous remote-sensing change detection, multimodality change detection, multiresolution change detection, Optical imaging, Optical sensors, Terrain factors}
}
@article{m_liu_cnn-transformer_2022,
	title        = {A {CNN}-Transformer Network With Multiscale Context Aggregation for Fine-Grained Cropland Change Detection},
	author       = {{M. Liu} and {Z. Chai} and {H. Deng} and {R. Liu}},
	volume       = 15,
	pages        = {4297--4306},
	doi          = {10.1109/JSTARS.2022.3177235},
	issn         = {2151-1535},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	date         = 2022
}
@article{m_noman_elgc-net_2024,
	title        = {{ELGC}-Net: Efficient Local–Global Context Aggregation for Remote Sensing Change Detection},
	author       = {{M. Noman} and {M. Fiaz} and {H. Cholakkal} and {S. Khan} and {F. S. Khan}},
	volume       = 62,
	pages        = {1--11},
	doi          = {10.1109/TGRS.2024.3362914},
	issn         = {1558-0644},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2024
}
@article{Mao2022MFATNetMF,
	title        = {MFATNet: Multi-Scale Feature Aggregation via Transformer for Remote Sensing Image Change Detection},
	author       = {Zan Mao and Xin-Yi Tong and Ze Luo and Honghai Zhang},
	year         = 2022,
	journal      = {Remote. Sens.},
	volume       = 14,
	pages        = 5379,
	xurlx          = {https://api.semanticscholar.org/CorpusID:253220641}
}
@article{Mei2024SCDSAMAS,
	title        = {SCD-SAM: Adapting Segment Anything Model for Semantic Change Detection in Remote Sensing Imagery},
	author       = {Liye Mei and Zhaoyi Ye and Chuan Xu and Hongzhu Wang and Ying Wang and Cheng Lei and Wei Yang and Yansheng Li},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--13},
	xurlx          = {https://api.semanticscholar.org/CorpusID:270196428}
}
@article{miao_snunet3_2024,
	title        = {{SNUNet}3+: A Full-Scale Connected Siamese Network and a Dataset for Cultivated Land Change Detection in High-Resolution Remote-Sensing Images},
	author       = {Miao, Lizhi and Li, X. and Zhou, Xinxin and Yao, Ling and Deng, Yamei and Hang, Tian and Zhou, Yuchao and Yang, Haozhou},
	volume       = 62,
	pages        = {1--18},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2024
}
@article{Noman2023RemoteSC,
	title        = {Remote Sensing Change Detection With Transformers Trained From Scratch},
	author       = {Mubashir Noman and Mustansar Fiaz and Hisham Cholakkal and Sanath Narayan and Rao Muhammad Anwer and Salman H. Khan and Fahad Shahbaz Khan},
	year         = 2023,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--14},
	xurlx          = {https://api.semanticscholar.org/CorpusID:258108040}
}
@article{noman2024remote,
	title        = {Remote sensing change detection with transformers trained from scratch},
	author       = {Noman, Mubashir and Fiaz, Mustansar and Cholakkal, Hisham and Narayan, Sanath and Anwer, Rao Muhammad and Khan, Salman and Khan, Fahad Shahbaz},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	publisher    = {IEEE}
}
@article{Osco2023TheSA,
	title        = {The Segment Anything Model (SAM) for Remote Sensing Applications: From Zero to One Shot},
	author       = {Lucas Prado Osco and Qiusheng Wu and Eduardo Lopes de Lemos and Wesley Nunes Gonçalves and Ana Paula Marques Ramos and Jonathan Li and Jos{\'e} Marcato Junior},
	year         = 2023,
	journal      = {ArXiv},
	volume       = {abs/2306.16623},
	xurlx          = {https://api.semanticscholar.org/CorpusID:259287018}
}
@article{Papadomanolaki2021ADM,
	title        = {A Deep Multitask Learning Framework Coupling Semantic Segmentation and Fully Convolutional LSTM Networks for Urban Change Detection},
	author       = {Maria Papadomanolaki and Maria Vakalopoulou and Konstantinos Karantzalos},
	year         = 2021,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 59,
	pages        = {7651--7668},
	xurlx          = {https://api.semanticscholar.org/CorpusID:233910177}
}
@article{pei_feature_2022,
	title        = {Feature Hierarchical Differentiation for Remote Sensing Image Change Detection},
	author       = {Pei, Gensheng and Zhang, Lulu},
	volume       = 19,
	pages        = {1--5},
	doi          = {10.1109/LGRS.2022.3193502},
	issn         = {1545-598X, 1558-0571},
	xurlx          = {https://ieeexplore.ieee.org/document/9837915/},
	xurlxdate      = {2023-10-23},
	abstract     = {Change detection ({CD}) is the localization of pixel-level differentiation between images in a speciﬁc setting, i.e., the same-spatial different-temporal scenario. For high-resolution remote sensing ({HRS}) images, {CD} models should guarantee detection accuracy for the changes of interest and ﬁlter background noise for other regions. To this end, we propose a timespeciﬁc model, dubbed feature hierarchical differentiation ({FHD}), to achieve change perception aimed at {HRS} images. Speciﬁcally, we present the time-speciﬁc feature ({TSF}) module to acquire each temporal image’s speciﬁc changes efﬁciently. Subsequently, the {TSFs} from multitemporal {HRS} images are adaptively fused by our proposed hierarchical differentiation ({HD}) module. Our {FHD} is subjected to elaborate experiments on four {CD} datasets. Quantitative and qualitative results outperform the existing state-of-the-art ({SOTA}) methods. The ablation study further demonstrates the effectiveness of the proposed modules. Code is available at https://github.com/{ZSVOS}/{FHD}.},
	journaltitle = {{IEEE} Geosci. Remote Sensing Lett.},
	date         = 2022,
	langid       = {english},
	file         = {Pei 和 Zhang - 2022 - Feature Hierarchical Differentiation for Remote Se.pdf:files/75/Pei 和 Zhang - 2022 - Feature Hierarchical Differentiation for Remote Se.pdf:application/pdf}
}
@article{peng_end--end_2019,
	title        = {End-to-End Change Detection for High Resolution Satellite Images Using Improved {UNet}++},
	author       = {Peng, Daifeng and Zhang, Yongjun and Guan, Haiyan},
	volume       = 11,
	number       = 11,
	doi          = {10.3390/rs11111382},
	issn         = {2072-4292},
	abstract     = {Change detection ({CD}) is essential to the accurate understanding of land surface changes using available Earth observation data. Due to the great advantages in deep feature representation and nonlinear problem modeling, deep learning is becoming increasingly popular to solve {CD} tasks in remote-sensing community. However, most existing deep learning-based {CD} methods are implemented by either generating difference images using deep features or learning change relations between pixel patches, which leads to error accumulation problems since many intermediate processing steps are needed to obtain final change maps. To address the above-mentioned issues, a novel end-to-end {CD} method is proposed based on an effective encoder-decoder architecture for semantic segmentation named {UNet}++, where change maps could be learned from scratch using available annotated datasets. Firstly, co-registered image pairs are concatenated as an input for the improved {UNet}++ network, where both global and fine-grained information can be utilized to generate feature maps with high spatial accuracy. Then, the fusion strategy of multiple side outputs is adopted to combine change maps from different semantic levels, thereby generating a final change map with high accuracy. The effectiveness and reliability of our proposed {CD} method are verified on very-high-resolution ({VHR}) satellite image datasets. Extensive experimental results have shown that our proposed approach outperforms the other state-of-the-art {CD} methods.},
	journaltitle = {Remote Sensing},
	date         = 2019,
	keywords     = {change detection, deep learning, encoder-decoder architecture, end-to-end, feature maps, multiple side-outputs fusion}
}
@article{Peng2024FDAFFNetAF,
	title        = {FDA-FFNet: A Feature-Distance Attention-Based Change Detection Network for Remote Sensing Image},
	author       = {Wen-Fang Peng and Wenzhong Shi and Min Zhang and Lukang Wang},
	year         = 2024,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 17,
	pages        = {2224--2233},
	xurlx          = {https://api.semanticscholar.org/CorpusID:266407564}
}
@article{Qiu2025DEDSAMAdaptingSA,
	title        = {DED-SAM:Adapting Segment Anything Model 2 for Dual Encoder–Decoder Change Detection},
	author       = {Junlong Qiu and Wei Liu and Xin Zhang and Erzhu Li and Lianpeng Zhang and Xing Li},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 18,
	pages        = {995--1006},
	xurlx          = {https://api.semanticscholar.org/CorpusID:273795136}
}
@inproceedings{Radford2021LearningTV,
	title        = {Learning Transferable Visual Models From Natural Language Supervision},
	author       = {Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
	year         = 2021,
	booktitle    = {International Conference on Machine Learning},
	xurlx          = {https://api.semanticscholar.org/CorpusID:231591445}
}
@article{Rao2021DenseCLIPLD,
	title        = {DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting},
	author       = {Yongming Rao and Wenliang Zhao and Guangyi Chen and Yansong Tang and Zheng Zhu and Guan Huang and Jie Zhou and Jiwen Lu},
	year         = 2021,
	journal      = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {18061--18070},
	xurlx          = {https://api.semanticscholar.org/CorpusID:244800733}
}
@article{Ronneberger2015UNetCN,
	title        = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	author       = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
	year         = 2015,
	journal      = {ArXiv},
	volume       = {abs/1505.04597},
	xurlx          = {https://api.semanticscholar.org/CorpusID:3719281}
}
@article{Shelhamer2014FullyCN,
	title        = {Fully convolutional networks for semantic segmentation},
	author       = {Evan Shelhamer and Jonathan Long and Trevor Darrell},
	year         = 2014,
	journal      = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {3431--3440},
	xurlx          = {https://api.semanticscholar.org/CorpusID:1629541}
}
@article{Shen2021S2LookingAS,
	title        = {S2Looking: A Satellite Side-Looking Dataset for Building Change Detection},
	author       = {Li Shen and Yao Lu and Hao Chen and Hao Wei and Donghai Xie and Jiabao Yue and Rui Chen and Y. Zhang and Ao Zhang and Shouye Lv and Bitao Jiang},
	year         = 2021,
	journal      = {Remote. Sens.},
	volume       = 13,
	pages        = 5094,
	xurlx          = {https://api.semanticscholar.org/CorpusID:236134438}
}
@article{shi_change_2020,
	title        = {Change Detection Based on Artificial Intelligence: State-of-the-Art and Challenges},
	author       = {Shi, Wenzhong and Zhang, Min and Zhang, Rui and Chen, Shanxiong and Zhan, Zhao},
	volume       = 12,
	number       = 10,
	doi          = {10.3390/rs12101688},
	abstract     = {Change detection based on remote sensing ({RS}) data is an important method of detecting changes on the Earth’s surface and has a wide range of applications in urban planning, environmental monitoring, agriculture investigation, disaster assessment, and map revision. In recent years, integrated artificial intelligence ({AI}) technology has become a research focus in developing new change detection methods. Although some researchers claim that {AI}-based change detection approaches outperform traditional change detection approaches, it is not immediately obvious how and to what extent {AI} can improve the performance of change detection. This review focuses on the state-of-the-art methods, applications, and challenges of {AI} for change detection. Specifically, the implementation process of {AI}-based change detection is first introduced. Then, the data from different sensors used for change detection, including optical {RS} data, synthetic aperture radar ({SAR}) data, street view images, and combined heterogeneous data, are presented, and the available open datasets are also listed. The general frameworks of {AI}-based change detection methods are reviewed and analyzed systematically, and the unsupervised schemes used in {AI}-based change detection are further analyzed. Subsequently, the commonly used networks in {AI} for change detection are described. From a practical point of view, the application domains of {AI}-based change detection methods are classified based on their applicability. Finally, the major challenges and prospects of {AI} for change detection are discussed and delineated, including (a) heterogeneous big data processing, (b) unsupervised {AI}, and (c) the reliability of {AI}. This review will be beneficial for researchers in understanding this field.},
	journaltitle = {Remote Sensing},
	date         = 2020
}
@article{shi_deeply_2022,
	title        = {A Deeply Supervised Attention Metric-Based Network and an Open Aerial Image Dataset for Remote Sensing Change Detection},
	author       = {Shi, Qian and Liu, Mengxi and Li, Shengchen and Liu, Xiaoping and Wang, Fei and Zhang, Liangpei},
	volume       = 60,
	pages        = {1--16},
	doi          = {10.1109/TGRS.2021.3085870},
	issn         = {0196-2892, 1558-0644},
	xurlx          = {https://ieeexplore.ieee.org/document/9467555/},
	xurlxdate      = {2023-10-23},
	abstract     = {Change detection ({CD}) aims to identify surface changes from bitemporal images. In recent years, deep learning ({DL})-based methods have made substantial breakthroughs in the ﬁeld of {CD}. However, {CD} results can be easily affected by external factors, including illumination, noise, and scale, which leads to pseudo-changes and noise in the detection map. To deal with these problems and achieve more accurate results, a deeply supervised ({DS}) attention metric-based network ({DSAMNet}) is proposed in this article. A metric module is employed in {DSAMNet} to learn change maps by means of deep metric learning, in which convolutional block attention modules ({CBAM}) are integrated to provide more discriminative features. As an auxiliary, a {DS} module is introduced to enhance the feature extractor’s learning ability and generate more useful features. Moreover, another challenge encountered by data-driven {DL} algorithms is posed by the limitations in change detection datasets ({CDDs}). Therefore, we create a {CD} dataset, Sun Yat-Sen University ({SYSU})-{CD}, for bitemporal image {CD}, which contains a total of 20 000 aerial image pairs of size 256 × 256. Experiments are conducted on both the {CDD} and the {SYSU}-{CD} dataset. Compared to other stateof-the-art methods, our network achieves the highest accuracy on both datasets, with an F1 of 93.69\% on the {CDD} dataset and 78.18\% on the {SYSU}-{CD} dataset.},
	journaltitle = {{IEEE} Trans. Geosci. Remote Sensing},
	date         = 2022,
	langid       = {english},
	file         = {Shi 等 - 2022 - A Deeply Supervised Attention Metric-Based Network.pdf:files/67/Shi 等 - 2022 - A Deeply Supervised Attention Metric-Based Network.pdf:application/pdf}
}
@article{Simonyan2014VeryDC,
	title        = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	author       = {Karen Simonyan and Andrew Zisserman},
	year         = 2014,
	journal      = {CoRR},
	volume       = {abs/1409.1556},
	xurlx          = {https://api.semanticscholar.org/CorpusID:14124313}
}
@article{Singha2023APPLeNetVA,
	title        = {APPLeNet: Visual Attention Parameterized Prompt Learning for Few-Shot Remote Sensing Image Generalization using CLIP},
	author       = {Mainak Singha and Ankit Jha and Bhupendra S. Solanki and Shirsha Bose and Biplab Banerjee},
	year         = 2023,
	journal      = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
	pages        = {2024--2034},
	xurlx          = {https://api.semanticscholar.org/CorpusID:258079339}
}
@inproceedings{Song2022CLIPMA,
	title        = {CLIP Models are Few-Shot Learners: Empirical Studies on VQA and Visual Entailment},
	author       = {Haoyu Song and Li Dong and Weinan Zhang and Ting Liu and Furu Wei},
	year         = 2022,
	booktitle    = {Annual Meeting of the Association for Computational Linguistics},
	xurlx          = {https://api.semanticscholar.org/CorpusID:247447209}
}
@article{Song2022RemoteSI,
	title        = {Remote Sensing Image Change Detection Transformer Network Based on Dual-Feature Mixed Attention},
	author       = {Xinyang Song and Zhen Hua and Jinjiang Li},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--16},
	xurlx          = {https://api.semanticscholar.org/CorpusID:252605199}
}
@article{Song2023AxialCA,
	title        = {Axial Cross Attention Meets CNN: Bibranch Fusion Network for Change Detection},
	author       = {Lei Song and Min Xia and Liguo Weng and Haifeng Lin and Ming Qian and Binyu Chen},
	year         = 2023,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 16,
	pages        = {32--43},
	xurlx          = {https://api.semanticscholar.org/CorpusID:253926260}
}
@inproceedings{Sun2022SUDANetAS,
	title        = {SUDANet: A Siamese UNet with Dense Attention Mechanism for Remote Sensing Image Change Detection},
	author       = {Chengzhen Sun and Chun Du and Jiangjiang Wu and Hao Chen},
	year         = 2022,
	booktitle    = {Chinese Conference on Pattern Recognition and Computer Vision},
	xurlx          = {https://api.semanticscholar.org/CorpusID:253448728}
}
@article{Sun2024SegmentAM,
	title        = {Segment Anything Model Guided Semantic Knowledge Learning For Remote Sensing Change Detection},
	author       = {Zixuan Sun and Huihui Song and Kaihua Zhang and Gang Dong and Lingyan Liang and Yaqian Zhao},
	year         = 2024,
	journal      = {ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages        = {5830--5834},
	xurlx          = {https://api.semanticscholar.org/CorpusID:268565413}
}
@article{t_zhu_fta-net_2025,
	title        = {{FTA}-Net: Frequency-Temporal-Aware Network for Remote Sensing Change Detection},
	author       = {{T. Zhu} and {Z. Zhao} and {M. Xia} and {J. Huang} and {L. Weng} and {K. Hu} and {H. Lin} and {W. Zhao}},
	volume       = 18,
	pages        = {3448--3460},
	doi          = {10.1109/JSTARS.2025.3525595},
	issn         = {2151-1535},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	date         = 2025
}
@inproceedings{tan_efficientnet_2019,
	title        = {{EfficientNet}: Rethinking Model Scaling for Convolutional Neural Networks},
	author       = {Tan, Mingxing and Le, Quoc},
	booktitle    = {Proceedings of the 36th International Conference on Machine Learning},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
	volume       = 97,
	pages        = {6105--6114},
	xurlx          = {https://proceedings.mlr.press/v97/tan19a.html},
	abstract     = {Convolutional Neural Networks ({ConvNets}) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are given. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on {MobileNets} and {ResNet}. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called {EfficientNets}, which achieve much better accuracy and efficiency than previous {ConvNets}. In particular, our {EfficientNet}-B7 achieves stateof-the-art 84.4\% top-1 / 97.1\% top-5 accuracy on {ImageNet}, while being 8.4x smaller and 6.1x faster on inference than the best existing {ConvNet} (Huang et al., 2018). Our {EfficientNets} also transfer well and achieve state-of-the-art accuracy on {CIFAR}-100 (91.7\%), Flower (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters.},
	editor       = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	date         = {2019-06-09}
}
@article{Tang2023InteractingEnhancingFT,
	title        = {Interacting-Enhancing Feature Transformer for Cross-Modal Remote-Sensing Image and Text Retrieval},
	author       = {Xu Tang and Yijing Wang and Jingjing Ma and Xiangrong Zhang and F. Liu and Licheng Jiao},
	year         = 2023,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 61,
	pages        = {1--15},
	xurlx          = {https://api.semanticscholar.org/CorpusID:258976435}
}
@article{Tian2022LargescaleDL,
	title        = {Large-scale deep learning based binary and semantic change detection in ultra high resolution remote sensing imagery: From benchmark datasets to urban application},
	author       = {Shiqi Tian and Yanfei Zhong and Zhuo Zheng and Ailong Ma and Xicheng Tan and L. Zhang},
	year         = 2022,
	journal      = {ISPRS Journal of Photogrammetry and Remote Sensing},
	xurlx          = {https://api.semanticscholar.org/CorpusID:252523312}
}
@article{ting_bai_deep_2023,
	title        = {Deep learning for change detection in remote sensing: a review},
	author       = {Ting Bai, Le Wang Dameng Yin and Li, Deren},
	volume       = 26,
	number       = 3,
	pages        = {262--288},
	doi          = {10.1080/10095020.2022.2085633},
	journaltitle = {Geo-spatial Information Science},
	date         = 2023
}
@article{Toker2024SatSynthAI,
	title        = {SatSynth: Augmenting Image-Mask Pairs Through Diffusion Models for Aerial Semantic Segmentation},
	author       = {Aysim Toker and Marvin Eisenberger and Daniel Cremers and Laura Leal-Taix'e},
	year         = 2024,
	journal      = {2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {27685--27695},
	xurlx          = {https://api.semanticscholar.org/CorpusID:268680796}
}
@inproceedings{Vaswani2017AttentionIA,
	title        = {Attention Is All You Need},
	author       = {Vaswani, Ashish and Shazeer, Noam M. and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	year         = 2017,
	booktitle    = {Neural Information Processing Systems}
}
@article{w_xie_mifnet_2025,
	title        = {{MIFNet}: Multi-Scale Interaction Fusion Network for Remote Sensing Image Change Detection},
	author       = {{W. Xie} and {W. Shao} and {D. Li} and {Y. Li} and {L. Fang}},
	volume       = 35,
	number       = 3,
	pages        = {2725--2739},
	doi          = {10.1109/TCSVT.2024.3494820},
	issn         = {1558-2205},
	journaltitle = {{IEEE} Transactions on Circuits and Systems for Video Technology},
	date         = {2025-03}
}
@article{wan_d-tnet_2022-3,
	title        = {D-{TNet}: Category-Awareness Based Difference-Threshold Alternative Learning Network for Remote Sensing Image Change Detection},
	author       = {Wan, Ling and Tian, Ye and Kang, Wenchao and Ma, Lei},
	volume       = 60,
	pages        = {1--16},
	doi          = {10.1109/TGRS.2022.3213925},
	abstract     = {Deep-learning-based change detection methods have achieved remarkable success through the feature learning capability of deep convolutions. However, the network structures of existing methods are simply modi铿乪d from the semantic segmentation models, ignoring the essential characteristics of change detection, thereby limiting their applications. In this work, we propose a category-awareness-based difference-threshold alternative-learning network (D-{TNet}) for remote sensing image change detection. Our motivation is to characterize the different change magnitudes for different land cover changes, and represent the semantic content differences of various objects. Thus, our D-{TNet} consists of a difference map ({DM}) learning path and a threshold map ({TM}) learning path, realizing selfadapting threshold selection by assigning each pixel a unique threshold. The two paths are alternatively optimized to make the {DM} more discriminative, as well as making the {TM} more adaptive. In addition, a category-awareness attention mechanism is introduced in D-{TNet}, which learns a pixel-to-category relationship to bene铿乼 in representing the heterogeneity of land covers. Finally, experimental results on three change detection datasets verify the effectiveness of our D-{TNet} in both visual and quantitative analyses. Code will be available at: https://www. researchgate.net/pro铿乴e/Ling-Wan-4.},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2022
}
@article{wang_hmcnet_2022-2,
	title        = {{HMCNet}: Hybrid Efficient Remote Sensing Images Change Detection Network Based on Cross-Axis Attention {MLP} and {CNN}},
	author       = {Wang, Liejun and Li, Haojin},
	volume       = 60,
	pages        = {1--14},
	doi          = {10.1109/TGRS.2022.3215244},
	abstract     = {As an important task in the 铿乪ld of remote sensing image interpretation, change detection ({CD}) has been extensively studied by scholars in recent years. Affected by the illumination and the environment during bitemporal images鈥?acquisition, there will be many pseudochanges, and the pseudochanges will seriously affect the effect of {CD}. Based on this, we propose a {CD} model named {HMCNet}, which introduces multilayer perceptron ({MLP}) into a convolutional neural network ({CNN})based {CD} model to form an {MLP}-{CNN} hybrid model. {HMCNet} has both the good feature extraction of {CNN} and the longterm dependence modeling ability of {MLP}, which can effectively overcome the interference of pseudochanges. In addition, the proposed cross-axis attention {MLP} can induce window attention of local features through shifted windows and, at the same time, form global attention to features through the interaction between information 铿俹ws on the cross-axis, which effectively improves the comprehensive performance of {MLP} block. Extensive experiments on three public benchmark datasets show that {HMCNet} can achieve better performance with fewer parameters and Flops, and still maintain good generalization ability with fewer train data.},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2022
}
@misc{wang_rsbuilding_2024,
	title        = {{RSBuilding}: Towards General Remote Sensing Image Building Extraction and Change Detection with Foundation Model},
	author       = {Wang, Mingze and Chen, Keyan and Su, Lili and Yan, Cilin and Xu, Sheng and Zhang, Haotian and Yuan, Pengcheng and Jiang, Xiaolong and Zhang, Baochang},
	date         = 2024
}
@article{Wang2017NonlocalNN,
	title        = {Non-local Neural Networks},
	author       = {X. Wang and Ross B. Girshick and Abhinav Kumar Gupta and Kaiming He},
	year         = 2017,
	journal      = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {7794--7803},
	xurlx          = {https://api.semanticscholar.org/CorpusID:4852647}
}
@article{Wang2019DeepHR,
	title        = {Deep High-Resolution Representation Learning for Visual Recognition},
	author       = {Jingdong Wang and Ke Sun and Tianheng Cheng and Borui Jiang and Chaorui Deng and Yang Zhao and Dong Liu and Yadong Mu and Mingkui Tan and Xinggang Wang and Wenyu Liu and Bin Xiao},
	year         = 2019,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume       = 43,
	pages        = {3349--3364},
	xurlx          = {https://api.semanticscholar.org/CorpusID:201124533}
}
@article{Wang2022ACC,
	title        = {A Cascaded Cross-Modal Network for Semantic Segmentation from High-Resolution Aerial Imagery and RAW Lidar Data},
	author       = {Yameng Wang and Bin Zhang and Yi Wan and Yongjun Zhang},
	year         = 2022,
	journal      = {IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium},
	pages        = {3480--3483},
	xurlx          = {https://api.semanticscholar.org/CorpusID:252590435}
}
@article{Wang2022AnES,
	title        = {An Empirical Study of Remote Sensing Pretraining},
	author       = {Di Wang and Jing Zhang and Bo Du and Guisong Xia and Dacheng Tao},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = {PP},
	pages        = {1--1},
	xurlx          = {https://api.semanticscholar.org/CorpusID:247996577}
}
@article{Wang2022HMCNetHE,
	title        = {HMCNet: Hybrid Efficient Remote Sensing Images Change Detection Network Based on Cross-Axis Attention MLP and CNN},
	author       = {Liejun Wang and Haojin Li},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--14},
	xurlx          = {https://api.semanticscholar.org/CorpusID:253251930}
}
@article{Wang2022SemanticIS,
	title        = {Semantic Image Synthesis via Diffusion Models},
	author       = {Weilun Wang and Jianmin Bao and Wen-gang Zhou and Dongdong Chen and Dong Chen and Lu Yuan and Houqiang Li},
	year         = 2022,
	journal      = {ArXiv},
	volume       = {abs/2207.00050},
	xurlx          = {https://api.semanticscholar.org/CorpusID:250243831}
}
@article{wang2022unetformer,
	title        = {UNetFormer: A UNet-like transformer for efficient semantic segmentation of remote sensing urban scene imagery},
	author       = {Wang, Libo and Li, Rui and Zhang, Ce and Fang, Shenghui and Duan, Chenxi and Meng, Xiaoliang and Atkinson, Peter M},
	year         = 2022,
	journal      = {ISPRS Journal of Photogrammetry and Remote Sensing},
	publisher    = {Elsevier},
	volume       = 190,
	pages        = {196--214}
}
@article{Wang2024HyperSIGMAHI,
	title        = {HyperSIGMA: Hyperspectral Intelligence Comprehension Foundation Model},
	author       = {Di Wang and Meiqi Hu and Yao Jin and Yuchun Miao and Jiaqi Yang and Yichu Xu and Xiaolei Qin and Jiaqi Ma and Lingyu Sun and Chenxing Li and Chuan Fu and Hongruixuan Chen and Chengxi Han and Naoto Yokoya and Jing Zhang and Minqiang Xu and Lin Liu and Lefei Zhang and Chen Wu and Bo Du and Dacheng Tao and Liang-Ying Zhang},
	year         = 2024,
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	volume       = {PP},
	xurlx          = {https://api.semanticscholar.org/CorpusID:270560828}
}
@article{Wang2024PyramidMambaRP,
	title        = {PyramidMamba: Rethinking Pyramid Feature Fusion with Selective Space State Model for Semantic Segmentation of Remote Sensing Imagery},
	author       = {Libo Wang and Dongxu Li and Sijun Dong and Xiaoliang Meng and Xiaokang Zhang and Danfeng Hong},
	year         = 2024,
	journal      = {ArXiv},
	volume       = {abs/2406.10828},
	xurlx          = {https://api.semanticscholar.org/CorpusID:270559885}
}
@article{Wang2024SummatorSubtractorNM,
	title        = {Summator–Subtractor Network: Modeling Spatial and Channel Differences for Change Detection},
	author       = {Leiquan Wang and Ye Fang and Zhongwei Li and Chunlei Wu and Mingming Xu and Mingwen Shao},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--12},
	xurlx          = {https://api.semanticscholar.org/CorpusID:266811217}
}
@article{vmmcd,
	title        = {VMMCD: VMamba-Based Multi-Scale Feature Guiding Fusion Network for Remote Sensing Change Detection},
	author       = {Chen, Zhong and Chen, Hanruo and Leng, Junsong and Zhang, Xiaolei and Gao, Qi and Dong, Weiyu},
	year         = 2025,
	journal      = {Remote Sensing},
	volume       = 17,
	number       = 11,
	doi          = {10.3390/rs17111840},
	issn         = {2072-4292},
	xurlx          = {https://www.mdpi.com/2072-4292/17/11/1840},
	article-number = 1840,
	abstract     = {Remote sensing image change detection, being a pixel-level dense prediction task, requires both high speed and high accuracy. The redundancy within the models and detection errors, particularly missed detections, generally affect accuracy and merit further research. Moreover, the former also leads to a reduction in speed. To guarantee the efficiency of change detection, encompassing both speed and accuracy, a VMamba-based Multi-scale Feature Guiding Fusion Network (VMMCD) is proposed. This network is capable of promptly modeling global relationships and realizing multi-scale feature interaction. Specifically, the Mamba backbone is adopted to replace the commonly used CNN and Transformer backbones. By leveraging VMamba’s global modeling ability with linear computational complexity, the computational resources needed for extracting global features are reduced. Secondly, considering the characteristics of the VMamba model, a compact and efficient lightweight network architecture is devised. The aim is to reduce the model’s redundancy, thereby avoiding the extraction or introduction of interfering and redundant information. As a result, the speed and accuracy of the model are both enhanced. Finally, the Multi-scale Feature Guiding Fusion (MFGF) module is developed, which strengthens the global modeling ability of VMamba. Additionally, it enriches the interaction among multi-scale features to address the common issue of missed detections in changed areas. The proposed network achieves competitive results on three publicly available datasets—SYSU-CD, WHU-CD, and S2Looking—and surpasses the current state-of-the-art (SOTA) methods on the SYSU-CD dataset, with an F1 of 83.35% and IoU of 71.45%. Moreover, for inputs of 256×256 size, it is more than three times faster than the current SOTA VMamba-based change detection model. This outstanding achievement demonstrates the effectiveness of our proposed approach.}
}
@article{wei_robust_2024,
	title        = {Robust change detection for remote sensing images based on temporospatial interactive attention module},
	author       = {Wei, Jinjiang and Sun, Kaimin and Li, Wenzhuo and Li, Wangbin and Gao, Song and Miao, Shunxia and Zhou, Qinhui and Liu, Junyi},
	volume       = 128,
	pages        = 103767,
	doi          = {https://doi.org/10.1016/j.jag.2024.103767},
	abstract     = {Change Detection ({CD}) is a vital monitoring method in Earth observation, especially pertinent for land-use analysis, city management, and disaster damage assessment. However, in the era of constellation interconnection and air-sky collaboration, the changes in the Regions Of Interest ({ROI}) cause many false detections due to geometric perspective rotation and temporal style difference. In response to these challenges, we introduce {CDNeXt}, this framework elucidates a robust and efficient method for combining Siamese networks based on the pre-trained backbone with the innovative Temporospatial Interactive Attention Module ({TIAM}) for remote sensing imagery. The {CDNeXt} can be categorized into four primary components: Encoder, Interactor, Decoder, and Detector. Notably, the Interactor, powered by {TIAM}, queries and rebuilds spatial perspective dependencies and temporal style correlations from binary temporal features extracted by the Encoder to enlarge the difference of {ROI} change. Culminating the process, the Detector integrates the hierarchical features generated by the Decoder, subsequently producing a binary change mask. We have achieved new State-Of-The-Art ({SOTA}) performance in change detection, with our method surpassing existing techniques on four benchmark datasets: an F1 score of 82.63\% on {SYSU}-{CD}, 87.14\% on {LEVIR}-{CD}+, 66.71\% on S2Looking, and 71.11\% {BANDON}. To further validate the effectiveness of the {TIAM}, we compared it to other attention modules in both interactive and non-interactive modes. Our code is available on {GitHub}: https://github.com/wjj282439449/{CDNeXt}.},
	journaltitle = {International Journal of Applied Earth Observation and Geoinformation},
	date         = 2024,
	keywords     = {Attention mechanism, Change detection, Remote sensing, Feature interaction}
}
@article{wu_cmtfnet_2023,
	title        = {{CMTFNet}: {CNN} and Multiscale Transformer Fusion Network for Remote-Sensing Image Semantic Segmentation},
	author       = {Wu, Honglin and Huang, Peng and Zhang, Min and Tang, Wenlong and Yu, Xinyu},
	volume       = 61,
	pages        = {1--12},
	doi          = {10.1109/TGRS.2023.3314641},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2023,
	keywords     = {Convolution, Data mining, Decoding, Feature extraction, Global contextual information, multiscale transformer, Remote sensing, remote-sensing image, semantic segmentation, Semantic segmentation, Transformers}
}
@article{Wu2023DatasetDMSD,
	title        = {DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models},
	author       = {Wei Wu and Yuzhong Zhao and Hao Chen and Yuchao Gu and Rui Zhao and Yefei He and Hong Zhou and Mike Zheng Shou and Chunhua Shen},
	year         = 2023,
	journal      = {ArXiv},
	volume       = {abs/2308.06160},
	xurlx          = {https://api.semanticscholar.org/CorpusID:260865973}
}
@article{Wu2023MedicalSA,
	title        = {Medical SAM Adapter: Adapting Segment Anything Model for Medical Image Segmentation},
	author       = {Junde Wu and Rao Fu and Huihui Fang and Yuanpei Liu and Zhao-Yang Wang and Yanwu Xu and Yueming Jin and Tal Arbel},
	year         = 2023,
	journal      = {Medical image analysis},
	volume       = 102,
	pages        = 103547,
	xurlx          = {https://api.semanticscholar.org/CorpusID:258309597}
}
@article{x_li_dsfi-cd_2025,
	title        = {{DSFI}-{CD}: Diffusion-Guided Spatial-Frequency-Domain Information Interaction for Remote Sensing Image Change Detection},
	author       = {{X. Li} and {Y. Tan} and {K. Liu} and {X. Wang} and {X. Zhou}},
	volume       = 63,
	pages        = {1--18},
	doi          = {10.1109/TGRS.2025.3544402},
	issn         = {1558-0644},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2025
}
@article{x_zhang_difunet_2022,
	title        = {{DifUnet}++: A Satellite Images Change Detection Network Based on Unet++ and Differential Pyramid},
	shorttitle   = {{DifUnet}++},
	author       = {{X. Zhang} and {Y. Yue} and {W. Gao} and {S. Yun} and {Q. Su} and {H. Yin} and {Y. Zhang}},
	volume       = 19,
	pages        = {1--5},
	doi          = {10.1109/LGRS.2021.3049370},
	issn         = {1558-0571},
	xurlx          = {https://ieeexplore.ieee.org/document/9333611/},
	xurlxdate      = {2023-10-23},
	journaltitle = {{IEEE} Geoscience and Remote Sensing Letters},
	date         = 2022,
	abstract     = {Change detection ({CD}) is one of the most important topics in the ﬁeld of remote sensing. In this letter, we propose an effective satellite images {CD} network named {DifUnet}++. As the presentation of explicit difference is more conducive to extract change features, we design a differential pyramid of two input images as the input of Unet++. Considering the scale diversity of changed regions in remote sensing images, a multiply sideouts fusion strategy is adopted to predict the detection results of different scales. Furthermore, a learning upsampling method is utilized to reﬁne the details of {CD}. The proposed architecture is evaluated on two public satellite image {CD} data sets. The experimental results show that our method performs much better than state-of-the-art methods.},
	langid       = {english},
	file         = {Zhang 等 - 2022 - DifUnet++ A Satellite Images Change Detection Net.pdf:files/107/Zhang 等 - 2022 - DifUnet++ A Satellite Images Change Detection Net.pdf:application/pdf}
}
@inproceedings{xiao_unified_2018,
	title        = {Unified Perceptual Parsing for Scene Understanding},
	author       = {Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},
	booktitle    = {European Conference on Computer Vision},
	xurlx          = {https://api.semanticscholar.org/CorpusID:50781105},
	date         = 2018
}
@inproceedings{xie_segformer_2021,
	title        = {{SegFormer}: Simple and Efficient Design for Semantic Segmentation with Transformers},
	author       = {Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Álvarez, José Manuel and Luo, Ping},
	booktitle    = {Neural Information Processing Systems},
	xurlx          = {https://api.semanticscholar.org/CorpusID:235254713},
	date         = 2021
}
@article{Xing2025FrequencyEnhancedMF,
	title        = {Frequency-Enhanced Mamba for Remote Sensing Change Detection},
	author       = {Yan Xing and Yunan Jia and Sen Gao and Jiali Hu and Rui Huang},
	year         = 2025,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	volume       = 22,
	pages        = {1--5},
	xurlx          = {https://api.semanticscholar.org/CorpusID:277075437}
}
@article{Xu2024HybridAT,
	title        = {Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection},
	author       = {Chuan Xu and Zhaoyi Ye and Liye Mei and Haonan Yu and Jianchen Liu and Yaxiaer Yalikun and Shuangtong Jin and Sheng Liu and Wei Yang and Cheng Lei},
	year         = 2024,
	journal      = {IEEE Transactions on Instrumentation and Measurement},
	volume       = 73,
	pages        = {1--14},
	xurlx          = {https://api.semanticscholar.org/CorpusID:268375803}
}
@article{Xu2023ProgressiveCA,
	title        = {Progressive Context-Aware Aggregation Network Combining Multi-Scale and Multi-Level Dense Reconstruction for Building Change Detection},
	author       = {Chuan Xu and Zhaoyi Ye and Liye Mei and Wei Yang and Yingying Hou and Sen-Qi Shen and Ouyang Wei and Zhiwei Ye},
	year         = 2023,
	journal      = {Remote. Sens.},
	volume       = 15,
	pages        = 1958,
	xurlx          = {https://api.semanticscholar.org/CorpusID:258034751}
}
@inproceedings{y_xing_sffce-cd_2025,
	title        = {SFFCE-CD: Spatial And Frequency Feature Cross Enhancement For Change Detection},
	author       = {Yan Xing and Jiali Hu and Binbin Jiang and Qingyi Zhao and Longxi Feng and Rui Huang},
	year         = 2025,
	booktitle    = {IEEE International Conference on Acoustics, Speech, and Signal Processing},
	xurlx          = {https://api.semanticscholar.org/CorpusID:276974126}
}
@article{y_zhou_stdf_2025,
	title        = {{STDF}: Joint Spatiotemporal Differences Based on {xLSTM} Dendritic Fusion Network for Remote Sensing Change Detection},
	author       = {{Y. Zhou} and {S. Zhou} and {D. Cheng} and {J. Li} and {Z. Hua}},
	pages        = {1--16},
	doi          = {10.1109/JSTARS.2025.3553930},
	issn         = {2151-1535},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	date         = 2025
}
@article{Yang2024DepthAU,
	title        = {Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data},
	author       = {Lihe Yang and Bingyi Kang and Zilong Huang and Xiaogang Xu and Jiashi Feng and Hengshuang Zhao},
	year         = 2024,
	journal      = {2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {10371--10381},
	xurlx          = {https://api.semanticscholar.org/CorpusID:267061016}
}
@article{ye_adjacent-level_2023,
	title        = {Adjacent-Level Feature Cross-Fusion With 3-D {CNN} for Remote Sensing Image Change Detection},
	author       = {Ye, Yuanxin and Wang, Mengmeng and Zhou, Liang and Lei, Guangyang and Fan, Jianwei and Qin, Yao},
	volume       = 61,
	pages        = {1--14},
	doi          = {10.1109/TGRS.2023.3305499},
	issn         = {0196-2892, 1558-0644},
	xurlx          = {https://ieeexplore.ieee.org/document/10221754/},
	xurlxdate      = {2023-11-28},
	abstract     = {Deep learning-based ({DL}-based) change detection ({CD}) using remote sensing ({RS}) images has received increasing attention in recent years. However, how to effectively extract and fuse the deep features of bi-temporal images for improving the accuracy of {CD} is still a challenge. To address that, a novel adjacent-level feature fusion network with 3-D convolution (named {AFCF}3D-Net) is proposed in this article. First, through the inner fusion property of 3-D convolution, we design a new feature fusion way that can simultaneously extract and fuse the feature information from bi-temporal images. Then, to alleviate the semantic gap between low-level features and highlevel features, we propose an adjacent-level feature cross-fusion ({AFCF}) module to aggregate complementary feature information between the adjacent levels. Furthermore, the full-scale skip connection strategy is introduced to improve the capability of pixel-wise prediction and the compactness of changed objects in the results. Finally, the proposed {AFCF}3D-Net has been validated on the three challenging {RS} {CD} datasets: the Wuhan building dataset ({WHU}-{CD}), the {LEVIR} building dataset ({LEVIR}-{CD}), and the Sun Yat-Sen University dataset ({SYSU}-{CD}). The results of quantitative analysis and qualitative comparison demonstrate that the proposed {AFCF}3D-Net achieves better performance compared to other state-of-the-art ({SOTA}) methods. The code for this work is available at https://github.com/wm-Githuber/ {AFCF}3D-Net.},
	journaltitle = {{IEEE} Trans. Geosci. Remote Sensing},
	date         = 2023,
	langid       = {english},
	file         = {Ye 等 - 2023 - Adjacent-Level Feature Cross-Fusion With 3-D CNN f.pdf:files/350/Ye 等 - 2023 - Adjacent-Level Feature Cross-Fusion With 3-D CNN f.pdf:application/pdf}
}
@article{conv_former,
	title        = {ConvFormer-CD: Hybrid CNN–Transformer With Temporal Attention for Detecting Changes in Remote Sensing Imagery},
	author       = {Yang, Feng and Li, Mengtao and Shu, Wenqiang and Qin, Anyong and Song, Tiecheng and Gao, Chenqiang and Xia, Gui-Song},
	year         = 2025,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 63,
	number       = {},
	pages        = {1--15},
	doi          = {10.1109/TGRS.2025.3544651},
	keywords     = {Feature extraction;Transformers;Semantics;Buildings;Remote sensing;Data mining;Convolutional neural networks;Decoding;Convolution;Adaptation models;Change detection (CD);convolutional neural network (CNN);hybrid network;self-attention;temporal attention}
}
@article{Ye2023AdjacentLevelFC,
	title        = {Adjacent-Level Feature Cross-Fusion With 3-D CNN for Remote Sensing Image Change Detection},
	author       = {Yuanxin Ye and Mengmeng Wang and Liang Zhou and Guangyang Lei and Jianwei Fan and Yao Qin},
	year         = 2023,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 61,
	pages        = {1--14},
	xurlx          = {https://api.semanticscholar.org/CorpusID:256808423}
}
@inproceedings{Ye2024SegGenSS,
	title        = {SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img Synthesis},
	author       = {Hanrong Ye and Jason Kuen and Qing Liu and Zhe L. Lin and Brian L. Price and Dan Xu},
	year         = 2024,
	booktitle    = {European Conference on Computer Vision},
	xurlx          = {https://api.semanticscholar.org/CorpusID:274023975}
}
@article{Yi2021CCAFFMNetDS,
	title        = {CCAFFMNet: Dual-spectral semantic segmentation network with channel-coordinate attention feature fusion module},
	author       = {Shi Yi and Junjie Li and Xi Liu and Xuesong Yuan},
	year         = 2021,
	journal      = {Neurocomputing},
	volume       = 482,
	pages        = {236--251},
	xurlx          = {https://api.semanticscholar.org/CorpusID:244751000}
}
@article{Yosinski2014HowTA,
	title        = {How transferable are features in deep neural networks?},
	author       = {Jason Yosinski and Jeff Clune and Yoshua Bengio and Hod Lipson},
	year         = 2014,
	journal      = {ArXiv},
	volume       = {abs/1411.1792},
	xurlx          = {https://api.semanticscholar.org/CorpusID:362467}
}
@article{Yuan2022STransUNetAS,
	title        = {STransUNet: A Siamese TransUNet-Based Remote Sensing Image Change Detection Network},
	author       = {Jianghua Yuan and Liejun Wang and Shuli Cheng},
	year         = 2022,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 15,
	pages        = {9241--9253},
	xurlx          = {https://api.semanticscholar.org/CorpusID:253333483}
}
@article{Yun2019CutMixRS,
	title        = {CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features},
	author       = {Sangdoo Yun and Dongyoon Han and Seong Joon Oh and Sanghyuk Chun and Junsuk Choe and Young Joon Yoo},
	year         = 2019,
	journal      = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {6022--6031},
	xurlx          = {https://api.semanticscholar.org/CorpusID:152282661}
}
@article{z_wang_bitemporal_2024,
	title        = {Bitemporal Attention Sharing Network for Remote Sensing Image Change Detection},
	author       = {{Z. Wang} and {G. Gu} and {M. Xia} and {L. Weng} and {K. Hu}},
	volume       = 17,
	pages        = {10368--10379},
	doi          = {10.1109/JSTARS.2024.3400925},
	issn         = {2151-1535},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	date         = 2024
}
@inproceedings{Zang2025ChangeDiffAM,
	title        = {ChangeDiff: A Multi-Temporal Change Detection Data Generator with Flexible Text Prompts via Diffusion Model},
	author       = {Qi Zang and Jiayi Yang and Shuang Wang and Dong Zhao and Wenjun Yi and Zhun Zhong},
	year         = 2025,
	booktitle    = {AAAI Conference on Artificial Intelligence},
	xurlx          = {https://api.semanticscholar.org/CorpusID:277761542}
}
@article{zhan_amfnet_2024,
	title        = {{AMFNet}: Attention-Guided Multi-Scale Fusion Network for Bi-Temporal Change Detection in Remote Sensing Images},
	author       = {Zhan, Zisen and Ren, Hongjin and Xia, Min and Lin, Haifeng and Wang, Xiaoya and Li, Xin},
	volume       = 16,
	number       = 10,
	doi          = {10.3390/rs16101765},
	issn         = {2072-4292},
	abstract     = {Change detection is crucial for evaluating land use, land cover changes, and sustainable development, constituting a significant component of Earth observation tasks. The difficulty in extracting features from high-resolution images, coupled with the complexity of image content, poses challenges for traditional change detection algorithms in terms of accuracy and applicability. The recent emergence of deep learning methods has led to substantial progress in the field of change detection. However, existing frameworks often involve the simplistic integration of bi-temporal features in specific areas, lacking the fusion of temporal information and semantic details in the images. In this paper, we propose an attention-guided multi-scale fusion network ({AMFNet}), which effectively integrates bi-temporal image features and diverse semantics at both the encoding and decoding stages. {AMFNet} utilizes a unique attention-guided mechanism to dynamically adjust feature fusion, enhancing adaptability and accuracy in change detection tasks. Our method intelligently incorporates temporal information into the deep learning model, considering the temporal dependency inherent in these tasks. We decode based on an interactive feature map, which improves the model’s understanding of evolving patterns over time. Additionally, we introduce multi-level supervised training to facilitate the learning of fused features across multiple scales. In comparison with different algorithms, our proposed method achieves F1 values of 0.9079, 0.8225, and 0.8809 in the {LEVIR}-{CD}, {GZ}-{CD}, and {SYSU}-{CD} datasets, respectively. Our model outperforms the {SOTA} model, {SAGNet}, by 0.69\% in terms of F1 and 1.15\% in terms of {IoU} on the {LEVIR}-{CD} dataset, by 2.8\% in terms of F1 and 1.79\% in terms of {IoU} on the {GZ}-{CD} dataset, and by 0.54\% in terms of F1 and 0.38\% in terms of {IoU} on the {SYSU}-{CD} dataset. The method proposed in this study can be applied to various complex scenarios, establishing a change detection method with strong model generalization capabilities.},
	journaltitle = {Remote Sensing},
	date         = 2024,
	keywords     = {change detection, deep learning, multi-scale supervised, remote sensing image}
}
@article{zhang_bifa_2024,
	title        = {{BiFA}: Remote Sensing Image Change Detection With Bitemporal Feature Alignment},
	author       = {Zhang, Haotian and Chen, Hao and Zhou, Chenyao and Chen, Keyan and Liu, Chenyang and Zou, Zhengxia and Shi, Zhenwei},
	volume       = 62,
	pages        = {1--17},
	doi          = {10.1109/TGRS.2024.3376673},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2024,
	keywords     = {Remote sensing, Feature extraction, Transformers, Task analysis, change detection ({CD}), Decoding, high-resolution optical remote sensing image, Bitemporal interaction ({BI}), feature alignment, flow field, implicit neural representation, Interference, Optical flow}
}
@article{zhang_cdmamba_2025,
	title        = {{CDMamba}: Incorporating Local Clues Into Mamba for Remote Sensing Image Binary Change Detection},
	author       = {Zhang, Haotian and Chen, Keyan and Liu, Chenyang and Chen, Hao and Zou, Zhengxia and Shi, Zhenwei},
	volume       = 63,
	pages        = {1--16},
	doi          = {10.1109/TGRS.2025.3545012},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2025,
	keywords     = {Remote sensing, Computational modeling, Convolutional neural networks, Feature extraction, Transformers, Visualization, change detection ({CD}), Computer vision, Artificial intelligence, Attention mechanisms, Bi-temporal interaction, high-resolution optical remote sensing image, Mamba, Spatiotemporal phenomena, state-space model}
}
@article{zhang_dc-mamba_2024,
	title        = {{DC}-Mamba: A Novel Network for Enhanced Remote Sensing Change Detection in Difficult Cases},
	author       = {Zhang, Junyi and Chen, Renwen and Liu, Fei and Liu, Hao and Zheng, Boyu and Hu, Chenyu},
	volume       = 16,
	number       = 22,
	doi          = {10.3390/rs16224186},
	issn         = {2072-4292},
	xurlx          = {https://www.mdpi.com/2072-4292/16/22/4186},
	abstract     = {Remote sensing change detection ({RSCD}) aims to utilize paired temporal remote sensing images to detect surface changes in the same area. Traditional {CNN}-based methods are limited by the size of the receptive field, making it difficult to capture the global features of remote sensing images. In contrast, Transformer-based methods address this issue with their powerful modeling capabilities. However, applying the Transformer architecture to image processing introduces a quadratic complexity problem, significantly increasing computational costs. Recently, the Mamba architecture based on state-space models has gained widespread application in the field of {RSCD} due to its excellent global feature extraction capabilities and linear complexity characteristics. Nevertheless, existing Mamba-based methods lack optimization for complex change areas, making it easy to lose shallow features or local features, which leads to poor performance on challenging detection cases and high-difficulty datasets. In this paper, we propose a Mamba-based {RSCD} network for difficult cases ({DC}-Mamba), which effectively improves the model’s detection capability in complex change areas. Specifically, we introduce the edge-feature enhancement ({EFE}) block and the dual-flow state-space ({DFSS}) block, which enhance the details of change edges and local features while maintaining the model’s global feature extraction capability. We propose a dynamic loss function to address the issue of sample imbalance, giving more attention to difficult samples during training. Extensive experiments on three change detection datasets demonstrate that our proposed {DC}-Mamba outperforms existing state-of-the-art methods overall and exhibits significant performance improvements in detecting difficult cases.},
	journaltitle = {Remote Sensing},
	date         = 2024
}
@article{zhang_global-aware_2023,
	title        = {Global-aware siamese network for change detection on remote sensing images},
	author       = {Zhang, Ruiqian and Zhang, Hanchao and Ning, Xiaogang and Huang, Xiao and Wang, Jiaming and Cui, Wei},
	volume       = 199,
	pages        = {61--72},
	doi          = {https://doi.org/10.1016/j.isprsjprs.2023.04.001},
	abstract     = {Change detection ({CD}) in remote sensing images is one of the most important technical options to identify changes in observations in an efficient manner. {CD} has a wide range of applications, such as land use investigation, urban planning, environmental monitoring and disaster mapping. However, the frequently occurring class imbalance problem brings huge challenges to the change detection applications. To address this issue, we develop a novel global-aware siamese network ({GAS}-Net), aiming to generate global-aware features for efficient change detection by incorporating the relationships between scenes and foregrounds. The proposed {GAS}-Net, consisting of the global-attention module ({GAM}) and foreground-awareness module ({FAM}) that both learns contextual relationships and enhances symbiotic relation learning between scene and foreground. The experimental results demonstrate the effectiveness and robustness of the proposed {GAS}-Net, achieving up to 91.21\% and 95.84\% F1 score on two widely used public datasets, i.e., Levir-{CD} and Lebedev-{CD} dataset. The source code is available at https://github.com/{xiaoxiangAQ}/{GAS}-Net.},
	journaltitle = {{ISPRS} Journal of Photogrammetry and Remote Sensing},
	date         = 2023,
	keywords     = {Change detection, Foreground awareness, Global attention, High-resolution images, Remote sensing}
}
@article{zhang_swinsunet_2022,
	title        = {{SwinSUNet}: Pure Transformer Network for Remote Sensing Image Change Detection},
	shorttitle   = {{SwinSUNet}},
	author       = {Zhang, Cui and Wang, Liejun and Cheng, Shuli and Li, Yongming},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	number       = {},
	pages        = {1--13},
	doi          = {10.1109/TGRS.2022.3160007},
	issn         = {0196-2892, 1558-0644},
	xurlx          = {https://ieeexplore.ieee.org/document/9736956/},
	xurlxdate      = {2023-10-23},
	abstract     = {Convolutional neural network ({CNN}) can extract effective semantic features, so it was widely used for remote sensing image change detection ({CD}) in the latest years. {CNN} has acquired great achievements in the ﬁeld of {CD}, but due to the intrinsic locality of convolution operation, it could not capture global information in space-time. The transformer was proposed in recent years and it can effectively extract global information, so it was used to solve computer vision ({CV}) tasks and achieved amazing success. In this article, we design a pure transformer network with Siamese U-shaped structure to solve {CD} problems and name it {SwinSUNet}. {SwinSUNet} contains encoder, fusion, and decoder, and all of them use Swin transformer blocks as basic units. Encoder has a Siamese structure based on hierarchical Swin transformer, so encoder can process bitemporal images in parallel and extract their multiscale features. Fusion is mainly responsible for the merge operation of the bitemporal features generated by the encoder. Like encoder, the decoder is also based on hierarchical Swin transformer. Different from the encoder, the decoder uses upsampling and merging ({UM}) block and Swin transformer blocks to recover the details of the change information. The encoder uses patch merging and Swin transformer blocks to generate effective semantic features. After the sequential process of these three modules, {SwinSUNet} will output the change maps. We did expensive experiments on four {CD} datasets, and in these experiments, {SwinSUNet} achieved better results than other related methods.},
	journaltitle = {{IEEE} Trans. Geosci. Remote Sensing},
	date         = 2022,
	langid       = {english},
	file         = {Zhang 等 - 2022 - SwinSUNet Pure Transformer Network for Remote Sen.pdf:files/83/Zhang 等 - 2022 - SwinSUNet Pure Transformer Network for Remote Sen.pdf:application/pdf},
	keywords     = {Transformers;Task analysis;Feature extraction;Merging;Convolution;Decoding;Semantics;Change detection (CD);deep learning;remote sensing image;transformer}
}
@article{Zhang2017mixupBE,
	title        = {mixup: Beyond Empirical Risk Minimization},
	author       = {Hongyi Zhang and Moustapha Ciss{\'e} and Yann Dauphin and David Lopez-Paz},
	year         = 2017,
	journal      = {ArXiv},
	volume       = {abs/1710.09412},
	xurlx          = {https://api.semanticscholar.org/CorpusID:3162051}
}
@article{Zhang2020ADS,
	title        = {A deeply supervised image fusion network for change detection in high resolution bi-temporal remote sensing images},
	author       = {Chenxiao Zhang and Peng Yue and Deodato Tapete and Liangcun Jiang and Boyi Shangguan and Li Huang and Guangchao Liu},
	year         = 2020,
	journal      = {Isprs Journal of Photogrammetry and Remote Sensing},
	volume       = 166,
	pages        = {183--200},
	xurlx          = {https://api.semanticscholar.org/CorpusID:225504855}
}
@article{Zhang2022ADHRCDNetAD,
	title        = {ADHR-CDNet: Attentive Differential High-Resolution Change Detection Network for Remote Sensing Images},
	author       = {Xiuwei Zhang and Mu Tian and Yinghui Xing and Yuanzeng Yue and Yanping Li and Hanlin Yin and Runliang Xia and Jin Jin and Yanning Zhang},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--13},
	xurlx          = {https://api.semanticscholar.org/CorpusID:253469752}
}
@article{Zhang2022SwinSUNetPT,
	title        = {SwinSUNet: Pure Transformer Network for Remote Sensing Image Change Detection},
	author       = {Cui Zhang and Liejun Wang and Shuli Cheng and Yongming Li},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = {PP},
	pages        = {1--1},
	xurlx          = {https://api.semanticscholar.org/CorpusID:247509609}
}
@article{Zhang2023AsymmetricCH,
	title        = {Asymmetric Cross-Attention Hierarchical Network Based on CNN and Transformer for Bitemporal Remote Sensing Images Change Detection},
	author       = {Xiaofeng Zhang and Shuli Cheng and Liejun Wang and Haojin Li},
	year         = 2023,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 61,
	pages        = {1--15},
	xurlx          = {https://api.semanticscholar.org/CorpusID:256970289}
}
@article{Zhang2023FasterSA,
	title        = {Faster Segment Anything: Towards Lightweight SAM for Mobile Applications},
	author       = {Chaoning Zhang and Dongshen Han and Yu Qiao and Jung Uk Kim and Sung-Ho Bae and Seungkyu Lee and Choong-Seon Hong},
	year         = 2023,
	journal      = {ArXiv},
	volume       = {abs/2306.14289},
	xurlx          = {https://api.semanticscholar.org/CorpusID:259251975}
}
@article{Zhang2023MultimodalAC,
	title        = {Multimodal Attention-Aware Convolutional Neural Networks for Classification of Hyperspectral and LiDAR Data},
	author       = {Haotian Zhang and Jing Yao and Li Ni and Lianru Gao and Min Huang},
	year         = 2023,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 16,
	pages        = {3635--3644},
	xurlx          = {https://api.semanticscholar.org/CorpusID:250224409}
}
@article{zhao_exchanging_2023,
	title        = {Exchanging Dual-Encoder–Decoder: A New Strategy for Change Detection With Semantic Guidance and Spatial Localization},
	author       = {Zhao, Sijie and Zhang, Xue-liang and Xiao, Pengfeng and He, Guangjun},
	volume       = 61,
	pages        = {1--16},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2023
}
@article{zhao_rs-mamba_2024,
	title        = {{RS}-Mamba for Large Remote Sensing Image Dense Prediction},
	author       = {Zhao, Sijie and Chen, Hao and Zhang, Xueliang and Xiao, Pengfeng and Bai, Lei and Ouyang, Wanli},
	volume       = 62,
	pages        = {1--14},
	doi          = {10.1109/TGRS.2024.3425540},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2024,
	keywords     = {Remote sensing, Change detection ({CD}), Feature extraction, Transformers, Task analysis, Context modeling, Complexity theory, deep learning, dense prediction, large remote sensing images, Predictive models, semantic segmentation ({SS}), state space model ({SSM}), very high resolution ({VHR})}
}
@article{zhao_triple-stream_2023,
	title        = {A Triple-Stream Network With Cross-Stage Feature Fusion for High-Resolution Image Change Detection},
	author       = {Zhao, Yu and Chen, Pan and Chen, Zhengchao and Bai, Yongqing and Zhao, Zhujun and Yang, Xuan},
	volume       = 61,
	pages        = {1--17},
	issn         = {0196-2892},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	date         = 2023
}
@article{Zhao2016PyramidSP,
	title        = {Pyramid Scene Parsing Network},
	author       = {Hengshuang Zhao and Jianping Shi and Xiaojuan Qi and Xiaogang Wang and Jiaya Jia},
	year         = 2016,
	journal      = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {6230--6239},
	xurlx          = {https://api.semanticscholar.org/CorpusID:5299559}
}
@article{Zhao2023FastSA,
	title        = {Fast Segment Anything},
	author       = {Xu Zhao and Wen-Yan Ding and Yongqi An and Yinglong Du and Tao Yu and Min Li and Ming Tang and Jinqiao Wang},
	year         = 2023,
	journal      = {ArXiv},
	volume       = {abs/2306.12156},
	xurlx          = {https://api.semanticscholar.org/CorpusID:259212104}
}
@article{Zhao2024GaMPFAF,
	title        = {GaMPF: A Full-Scale Gated Message Passing Framework Based on Collaborative Estimation for VHR Remote Sensing Image Change Detection},
	author       = {Xiaoyang Zhao and Keyun Zhao and Siyao Li and Chuanming Song and Xianghai Wang},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--13},
	xurlx          = {https://api.semanticscholar.org/CorpusID:266394533}
}
@article{Zheng2020RethinkingSS,
	title        = {Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers},
	author       = {Sixiao Zheng and Jiachen Lu and Hengshuang Zhao and Xiatian Zhu and Zekun Luo and Yabiao Wang and Yanwei Fu and Jianfeng Feng and Tao Xiang and Philip H. S. Torr and Li Zhang},
	year         = 2020,
	journal      = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {6877--6886},
	xurlx          = {https://api.semanticscholar.org/CorpusID:229924195}
}
@article{Zheng2022HFANetHF,
	title        = {HFA-Net: High frequency attention siamese network for building change detection in VHR remote sensing images},
	author       = {Hanhong Zheng and Maoguo Gong and Tongfei Liu and Fenlong Jiang and Tao Zhan and Di Lu and Mingyang Zhang},
	year         = 2022,
	journal      = {Pattern Recognit.},
	volume       = 129,
	pages        = 108717,
	xurlx          = {https://api.semanticscholar.org/CorpusID:248250134}
}
@article{Zhou2022JointFD,
	title        = {Joint Frequency-Spatial Domain Network for Remote Sensing Optical Image Change Detection},
	author       = {Yuan Zhou and Yanjie Feng and Shuwei Huo and Xiaofeng Li},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--14},
	xurlx          = {https://api.semanticscholar.org/CorpusID:251330588}
}
@article{Zhou2024MultistageIN,
	title        = {Multistage Interaction Network for Remote Sensing Change Detection},
	author       = {Meng Zhou and Weixian Qian and Kan Ren},
	year         = 2024,
	journal      = {Remote. Sens.},
	volume       = 16,
	pages        = 1077,
	xurlx          = {https://api.semanticscholar.org/CorpusID:268570138}
}
@article{zhu_land-useland-cover_2022-1,
	title        = {Land-Use/Land-Cover change detection based on a Siamese global learning framework for high spatial resolution remote sensing imagery},
	author       = {Zhu, Qiqi and Guo, Xi and Deng, Weihuan and Shi, Sunan and Guan, Qingfeng and Zhong, Yanfei and Zhang, Liangpei and Li, Deren},
	volume       = 184,
	pages        = {63--78},
	issn         = {09242716},
	abstract     = {Due to the abundant features of high spatial resolution ({HSR}) remote sensing images, change detection of these images is crucial to understanding the land-use and land-cover ({LULC}) changes. However, previous works mostly focus on traditional binary change detection without considering the semantic information of the change classes. The latest progress of deep learning ({DL}) shows its advantages in {HSR} remote sensing images change detection. However, due to the large number of parameter calculations, the {DL} network always requires a large quantity of labeled data. In addition, {DL} methods for change detection usually follow a patch-based learning framework, which considers only the local area and leads to a sample imbalance problem for semantic change detection. To address the above issues, we first proposed a Siamese global learning (Siam-{GL}) framework, which is a novel semantic change detction framework for {HSR} remote sensing images. In Siam-{GL}, the Siamese architecture with shared parameters is constructed to effectively extract the representative features of bi-temporal {HSR} remote sensing images. The global hierarchical (G-H) sampling mechanism is designed to address the imbalanced training sample problem with insufficient samples. Furthermore, the binary change mask is added between the encoder and decoder to weaken the influence of the no-change regional background on the change regional foreground, further improving the accuracy of the proposed framework. The experimental results obtained with three diverse {HSR} datasets of typical Chinese cities demonstrated that the Siam-{GL} framework outperforms the advanced semantic change detection methods in terms of both quantity and quality. Moreover, to verify the generalization performance of the Siam-{GL} framework, a larger dataset was used for evaluation, and the results show that the Siam-{GL} framework has strong generalization performance.},
	journaltitle = {{ISPRS} Journal of Photogrammetry and Remote Sensing},
	date         = {2022-01-01}
}
@article{Deng2023TChangeAH,
	title        = {TChange: A Hybrid Transformer-CNN Change Detection Network},
	author       = {Yupeng Deng and Yu Meng and Jingbo Chen and Anzhi Yue and Diyou Liu and Jingbo Chen},
	year         = 2023,
	journal      = {Remote. Sens.},
	volume       = 15,
	pages        = 1219,
	xurlx          = {https://api.semanticscholar.org/CorpusID:257176698}
}
@article{Zhang2024DCMambaAN,
	title        = {DC-Mamba: A Novel Network for Enhanced Remote Sensing Change Detection in Difficult Cases},
	author       = {Junyi Zhang and Renwen Chen and Fei Liu and Hao Liu and Boyu Zheng and Chenyu Hu},
	year         = 2024,
	journal      = {Remote Sensing},
	xurlx          = {https://api.semanticscholar.org/CorpusID:273985891}
}
@article{Dong2025SpectMambaRS,
	title        = {SpectMamba: Remote sensing change detection network integrating frequency and visual state space model},
	author       = {Zhiwei Dong and Dapeng Cheng and Jinjiang Li},
	year         = 2025,
	journal      = {Expert Systems with Applications},
	xurlx          = {https://api.semanticscholar.org/CorpusID:278471083}
}
@article{Song_Displays_2025_p103097,
	title        = {{Mamba-MSCCA-Net: Efficient change detection for remote sensing images}},
	author       = {Zichen Song and Yuxin Wu and Sitan Huang},
	year         = 2025,
	journal      = {Displays},
	pages        = 103097,
	doi          = {10.1016/j.displa.2025.103097}
}
@article{CHXB201710028,
	title        = {多时相遥感影像变化检测的现状与展望},
	author       = {张良培 and 武辰},
	year         = 2017,
	journal      = {测绘学报},
	volume       = 46,
	number       = 10,
	pages        = {1447--1459},
	issn         = {1001-1595}
}
@phdthesis{1024002737.nh,
	title        = {基于差分特征学习与注意力机制的图像变化检测方法及应用研究},
	author       = {薛丁华},
	year         = 2023,
	school       = {陕西科技大学}
}
@article{Wang_RemoteSens_2023_v15_p3517,
	title        = {{High-Resolution Remote Sensing Image Change Detection Method Based on Improved Siamese U-Net}},
	author       = {Qing Wang and Mengqi Li and Gongquan Li and Jiling Zhang and Shuoyue Yan and Zhuoran Chen and Xiaodong Zhang and Guanzhou Chen},
	year         = 2023,
	journal      = {Remote. Sens.},
	volume       = 15,
	number       = 14,
	pages        = 3517,
	doi          = {10.3390/rs15143517},
	abstract     = {Focusing on problems of blurred detection boundary, small target miss detection, and more pseudo changes in high-resolution remote sensing image change detection, a change detection algorithm based on Siamese neural networks is proposed. Siam-FAUnet can implement end-to-end change detection tasks. Firstly, the improved VGG16 is utilized as an encoder to extract the image features. Secondly, the atrous spatial pyramid pooling module is used to increase the receptive field of the model to make full use of the global information of the image and obtain the multi-scale contextual information of the image. The flow alignment module is used to fuse the low-level features in the encoder to the decoder and solve the problem of semantic misalignment caused by the direct concatenation of features when the features are fused, so as to obtain the change region of the image. The experiments are trained and tested using publicly available CDD and SZTAKI datasets. The results show that the evaluation metrics of the Siam-FAUnet model are improved compared to the baseline model, in which the F1-score is improved by 4.00{\%} on the CDD and by 7.32{\%} and 2.62{\%} on the sub-datasets of SZTAKI (SZADA and TISZADOB), respectively; compared to other state-of-the-art methods, the Siam-FAUnet model has improved in both evaluation metrics, indicating that the model has a good detection performance.}
}
@article{Wang2024CFGCNGC,
	title        = {CF-GCN: Graph Convolutional Network for Change Detection in Remote Sensing Images},
	author       = {Wei Wang and Cong Liu and Guanqun Liu and Xin Wang},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--13},
	xurlx          = {https://api.semanticscholar.org/CorpusID:267287875}
}
@article{Yu2024RemoteSI,
	title        = {Remote Sensing Image Change Detection Based on Deep Learning: Multi-Level Feature Cross-Fusion with 3D-Convolutional Neural Networks},
	author       = {Sibo Yu and Chen Tao and Guang Zhang and Yubo Xuan and Xiaodong Wang},
	year         = 2024,
	journal      = {Applied Sciences},
	xurlx          = {https://api.semanticscholar.org/CorpusID:271389117}
}
@inproceedings{Larson2007FlashVF,
	title        = {Flash Video for Professionals: Expert Techniques for Integrating Video on the Web},
	author       = {Lisa A. Larson and Ren Costantini},
	year         = 2007,
	xurlx          = {https://api.semanticscholar.org/CorpusID:60792600}
}
@article{Huang2021ObjectLevelRS,
	title        = {Object-Level Remote Sensing Image Augmentation Using U-Net-Based Generative Adversarial Networks},
	author       = {Jian Huang and Shan Liu and Yutian Tang and Xiushan Zhang},
	year         = 2021,
	journal      = {Wirel. Commun. Mob. Comput.},
	volume       = 2021,
	pages        = {1230279:1--1230279:12},
	xurlx          = {https://api.semanticscholar.org/CorpusID:237521649}
}
@article{Goodfellow2021GenerativeAN,
	title        = {Generative Adversarial Networks},
	author       = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},
	year         = 2021,
	journal      = {2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)},
	pages        = {1--7},
	xurlx          = {https://api.semanticscholar.org/CorpusID:1033682}
}
@article{Ho2020DenoisingDP,
	title        = {Denoising Diffusion Probabilistic Models},
	author       = {Jonathan Ho and Ajay Jain and P. Abbeel},
	year         = 2020,
	journal      = {ArXiv},
	volume       = {abs/2006.11239},
	xurlx          = {https://api.semanticscholar.org/CorpusID:219955663}
}
@article{Zheng2024Changen2MR,
	title        = {Changen2: Multi-Temporal Remote Sensing Generative Change Foundation Model},
	author       = {Zhuo Zheng and Stefano Ermon and Dongjun Kim and Liangpei Zhang and Yanfei Zhong},
	year         = 2024,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume       = 47,
	pages        = {725--741},
	xurlx          = {https://api.semanticscholar.org/CorpusID:270737951}
}
@article{Zheng2023ScalableMR,
	title        = {Scalable Multi-Temporal Remote Sensing Change Data Generation via Simulating Stochastic Change Process},
	author       = {Zhuo Zheng and Shiqi Tian and Ailong Ma and L. Zhang and Yanfei Zhong},
	year         = 2023,
	journal      = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {21761--21770},
	xurlx          = {https://api.semanticscholar.org/CorpusID:263311033}
}
@article{YGXB202406011,
	title        = {基于方向相位稠密特征的多传感器遥感影像配准方法和系统},
	author       = {叶沅鑫 and     王蒙蒙 and     杨超 and     喻智睿 and 葛旭明},
	year         = 2024,
	journal      = {遥感学报},
	volume       = 28,
	number       = {06},
	pages        = {1525--1538},
	issn         = {1007-4619}
}
@article{WHCH202405001,
	title        = {一阶高斯方向可调滤波器引导的多源卫星遥感影像配准方法},
	author       = {王密 and     樊仲藜 and     皮英冬 and 刘玉轩},
	year         = 2024,
	journal      = {武汉大学学报(信息科学版)},
	volume       = 49,
	number       = {05},
	pages        = {681--690},
	doi          = {10.13203/j.whugis20230244},
	issn         = {1671-8860}
}
@article{CHXB202207001,
	title        = {多时相遥感影像的变化检测研究现状与展望},
	author       = {张祖勋 and     姜慧伟 and     庞世燕 and 胡翔云},
	year         = 2022,
	journal      = {测绘学报},
	volume       = 51,
	number       = {07},
	pages        = {1091--1107},
	issn         = {1001-1595}
}
@article{Chen2020DASNetDA,
	title        = {DASNet: Dual Attentive Fully Convolutional Siamese Networks for Change Detection in High-Resolution Satellite Images},
	author       = {Jie Chen and Ziyang Yuan and Jian Peng and Li Chen and Haozhe Huang and Jiawei Zhu and Yu Liu and Haifeng Li},
	year         = 2020,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 14,
	pages        = {1194--1206},
	xurlx          = {https://api.semanticscholar.org/CorpusID:212633986}
}
@article{McInnes2018UMAPUM,
	title        = {UMAP: Uniform Manifold Approximation and Projection},
	author       = {Leland McInnes and John Healy and Nathaniel Saul and Lukas Gro{\ss}berger},
	year         = 2018,
	journal      = {J. Open Source Softw.},
	volume       = 3,
	pages        = 861,
	xurlx          = {https://api.semanticscholar.org/CorpusID:53244226}
}
@article{cheng2024harmony,
	title        = {Harmony in diversity: Content cleansing change detection framework for very-high-resolution remote-sensing images},
	author       = {Cheng, Mofan and He, Wei and Li, Zhuohong and Yang, Guangyi and Zhang, Hongyan},
	year         = 2024,
	journal      = {ISPRS Journal of Photogrammetry and Remote Sensing},
	publisher    = {Elsevier},
	volume       = 218,
	pages        = {1--19}
}
@article{jiang2020change,
	title        = {Change detection in heterogeneous optical and SAR remote sensing images via deep homogeneous feature fusion},
	author       = {Jiang, Xiao and Li, Gang and Liu, Yu and Zhang, Xiao-Ping and He, You},
	year         = 2020,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	publisher    = {IEEE},
	volume       = 13,
	pages        = {1551--1566}
}
@article{li2021deep,
	title        = {A deep translation (GAN) based change detection network for optical and SAR remote sensing images},
	author       = {Li, Xinghua and Du, Zhengshun and Huang, Yanyuan and Tan, Zhenyu},
	year         = 2021,
	journal      = {ISPRS Journal of Photogrammetry and Remote Sensing},
	publisher    = {Elsevier},
	volume       = 179,
	pages        = {14--34}
}
@inproceedings{chen2022semantic,
	title        = {Semantic decoupled representation learning for remote sensing image change detection},
	author       = {Chen, Hao and Zao, Yifan and Liu, Liqin and Chen, Song and Shi, Zhenwei},
	year         = 2022,
	booktitle    = {IGARSS 2022-2022 IEEE International Geoscience and Remote Sensing Symposium},
	pages        = {1051--1054},
	organization = {IEEE}
}
@article{Fang2022ContentInvariantDL,
	title        = {Content-Invariant Dual Learning for Change Detection in Remote Sensing Images},
	author       = {Bo Fang and Gang Chen and Guichong Ouyang and Jifa Chen and Rong Kou and Lizhe Wang},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--17},
	xurlx          = {https://api.semanticscholar.org/CorpusID:234107567}
}
@article{Dai2024DADRHCDAD,
	title        = {DADR-HCD: A Deep Domain Adaptation and Disentangled Representation Network for Unsupervised Heterogeneous Change Detection},
	author       = {Anjin Dai and Jianyu Yang and Tingting Zhang and Bingbo Gao and Kaixuan Tang and Xinyue Chen},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--15},
	xurlx          = {https://api.semanticscholar.org/CorpusID:269963824}
}
@article{He2015DeepRL,
	title        = {Deep Residual Learning for Image Recognition},
	author       = {Kaiming He and X. Zhang and Shaoqing Ren and Jian Sun},
	year         = 2015,
	journal      = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {770--778},
	xurlx          = {https://api.semanticscholar.org/CorpusID:206594692}
}
@article{johnson1998change,
	title        = {Change vector analysis: A technique for the multispectral monitoring of land cover and condition},
	author       = {Johnson, R Dˈ and Kasischke, Eric S},
	year         = 1998,
	journal      = {International journal of remote sensing},
	publisher    = {Taylor \& Francis},
	volume       = 19,
	number       = 3,
	pages        = {411--426}
}
@article{deng2008pca,
	title        = {PCA-based land-use change detection and analysis using multitemporal and multisensor satellite data},
	author       = {Deng, JS and Wang, Ke and Deng, YH and Qi, GJ},
	year         = 2008,
	journal      = {International Journal of Remote Sensing},
	publisher    = {Taylor \& Francis},
	volume       = 29,
	number       = 16,
	pages        = {4823--4838}
}
@inproceedings{zhou2018unet++,
	title        = {Unet++: A nested u-net architecture for medical image segmentation},
	author       = {Zhou, Zongwei and Rahman Siddiquee, Md Mahfuzur and Tajbakhsh, Nima and Liang, Jianming},
	year         = 2018,
	booktitle    = {International workshop on deep learning in medical image analysis},
	pages        = {3--11},
	organization = {Springer}
}
@article{zhu2023ecfnet,
	title        = {ECFNet: A Siamese network with fewer FPs and fewer FNs for change detection of remote-sensing images},
	author       = {Zhu, Siyuan and Song, Yonghong and Zhang, Yu and Zhang, Yuanlin},
	year         = 2023,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	publisher    = {IEEE},
	volume       = 20,
	pages        = {1--5}
}
@article{qu2021change,
	title        = {Change detection in synthetic aperture radar images using a dual-domain network},
	author       = {Qu, Xiaofan and Gao, Feng and Dong, Junyu and Du, Qian and Li, Heng-Chao},
	year         = 2021,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	publisher    = {IEEE},
	volume       = 19,
	pages        = {1--5}
}
@inproceedings{bandara2022transformer,
	title        = {A transformer-based siamese network for change detection},
	author       = {Bandara, Wele Gedara Chaminda and Patel, Vishal M},
	year         = 2022,
	booktitle    = {IGARSS 2022-2022 IEEE International Geoscience and Remote Sensing Symposium},
	pages        = {207--210},
	organization = {IEEE}
}
@article{tang2024siamese,
	title        = {A Siamese Swin-Unet for image change detection},
	author       = {Tang, Yizhuo and Cao, Zhengtao and Guo, Ningbo and Jiang, Mingyong},
	year         = 2024,
	journal      = {Scientific Reports},
	publisher    = {Nature Publishing Group UK London},
	volume       = 14,
	number       = 1,
	pages        = 4577
}
@article{liu2022pa,
	title        = {PA-Former: Learning prior-aware transformer for remote sensing building change detection},
	author       = {Liu, Mengxi and Shi, Qian and Chai, Zhuoqun and Li, Jianlong},
	year         = 2022,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	publisher    = {IEEE},
	volume       = 19,
	pages        = {1--5}
}
@article{zhang2023asymmetric,
	title        = {Asymmetric cross-attention hierarchical network based on CNN and transformer for bitemporal remote sensing images change detection},
	author       = {Zhang, Xiaofeng and Cheng, Shuli and Wang, Liejun and Li, Haojin},
	year         = 2023,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	publisher    = {IEEE},
	volume       = 61,
	pages        = {1--15}
}
@article{chen2024changemamba,
	title        = {ChangeMamba: Remote sensing change detection with spatiotemporal state space model},
	author       = {Chen, Hongruixuan and Song, Jian and Han, Chengxi and Xia, Junshi and Yokoya, Naoto},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	publisher    = {IEEE},
	volume       = 62,
	pages        = {1--20}
}
@article{liu2025cd,
	title        = {CD-STMamba: Towards Remote Sensing Image Change Detection With Spatio-Temporal Interaction Mamba Model},
	author       = {Liu, Shanwei and Wang, Shuaipeng and Zhang, Wei and Zhang, Tao and Xu, Mingming and Yasir, Muhammad and Wei, Shiqing},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	publisher    = {IEEE}
}
@article{guo2025cd,
	title        = {AM-CD: Joint Attention and Mamba for Remote Sensing Image Change Detection},
	author       = {Guo, Yingting and Xu, Yan and Tang, Guo and Yu, Zhiqun and Tang, Qunli and others},
	year         = 2025,
	journal      = {Neurocomputing},
	publisher    = {Elsevier},
	pages        = 130607
}
@article{ding2024adapting,
	title        = {Adapting segment anything model for change detection in VHR remote sensing images},
	author       = {Ding, Lei and Zhu, Kun and Peng, Daifeng and Tang, Hao and Yang, Kuiwu and Bruzzone, Lorenzo},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	publisher    = {IEEE},
	volume       = 62,
	pages        = {1--11}
}
@article{zheng2024segment,
	title        = {Segment any change},
	author       = {Zheng, Zhuo and Zhong, Yanfei and Zhang, Liangpei and Ermon, Stefano},
	year         = 2024,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 37,
	pages        = {81204--81224}
}
@article{mei2024scd,
	title        = {SCD-SAM: Adapting segment anything model for semantic change detection in remote sensing imagery},
	author       = {Mei, Liye and Ye, Zhaoyi and Xu, Chuan and Wang, Hongzhu and Wang, Ying and Lei, Cheng and Yang, Wei and Li, Yansheng},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	publisher    = {IEEE},
	volume       = 62,
	pages        = {1--13}
}
@article{dong2024changeclip,
	title        = {ChangeCLIP: Remote sensing change detection with multimodal vision-language representation learning},
	author       = {Dong, Sijun and Wang, Libo and Du, Bo and Meng, Xiaoliang},
	year         = 2024,
	journal      = {ISPRS Journal of Photogrammetry and Remote Sensing},
	publisher    = {Elsevier},
	volume       = 208,
	pages        = {53--69}
}
@inproceedings{chen2024time,
	title        = {Time travelling pixels: Bitemporal features integration with foundation model for remote sensing image change detection},
	author       = {Chen, Keyan and Liu, Chengyang and Li, Wenyuan and Liu, Zili and Chen, Hao and Zhang, Haotian and Zou, Zhengxia and Shi, Zhenwei},
	year         = 2024,
	booktitle    = {IGARSS 2024-2024 IEEE International Geoscience and Remote Sensing Symposium},
	pages        = {8581--8584},
	organization = {IEEE}
}
@article{li2024new,
	title        = {A new learning paradigm for foundation model-based remote-sensing change detection},
	author       = {Li, Kaiyu and Cao, Xiangyong and Meng, Deyu},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	publisher    = {IEEE},
	volume       = 62,
	pages        = {1--12}
}
@article{wang2024rsbuilding,
	title        = {Rsbuilding: Towards general remote sensing image building extraction and change detection with foundation model},
	author       = {Wang, Mingze and Su, Lili and Yan, Cilin and Xu, Sheng and Yuan, Pengcheng and Jiang, Xiaolong and Zhang, Baochang},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	publisher    = {IEEE}
}
@article{qiu2024novel,
	title        = {A novel change detection method based on visual language from high-resolution remote sensing images},
	author       = {Qiu, Junlong and Liu, Wei and Zhang, Hui and Li, Erzhu and Zhang, Lianpeng and Li, Xing},
	year         = 2024,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	publisher    = {IEEE}
}
@article{zhu2025semantic,
	title        = {Semantic-cd: Remote sensing image semantic change detection towards open-vocabulary setting},
	author       = {Zhu, Yongshuo and Li, Lu and Chen, Keyan and Liu, Chenyang and Zhou, Fugen and Shi, Zhenwei},
	year         = 2025,
	journal      = {arXiv preprint arXiv:2501.06808}
}
@article{Lv2022LandCC,
	title        = {Land Cover Change Detection With Heterogeneous Remote Sensing Images: Review, Progress, and Perspective},
	author       = {Zhiyong Lv and Haitao Huang and Xinghua Li and Minghua Zhao and J{\'o}n Atli Benediktsson and Weiwei Sun and Nicola Falco},
	year         = 2022,
	journal      = {Proceedings of the IEEE},
	volume       = 110,
	pages        = {1976--1991},
	xurlx          = {https://api.semanticscholar.org/CorpusID:253695791}
}
@article{Ceng2025DeepLF,
	title        = {Deep learning for change detection in remote sensing： A review and new outlooks},
	author       = {Gong Ceng and Guangxing Wang and Junwei Han},
	year         = 2025,
	journal      = {National Remote Sensing Bulletin},
	xurlx          = {https://api.semanticscholar.org/CorpusID:277989318}
}
@inproceedings{Mishra2017ChangeDT,
	title        = {Change Detection Techniques in Remote Sensing: A Review},
	author       = {Shivangi Mishra and Priyanka Shrivastava and Priyanka Dhurvey},
	year         = 2017,
	xurlx          = {https://api.semanticscholar.org/CorpusID:133632415}
}
@article{Wu2024UNetLikeRS,
	title        = {UNet-Like Remote Sensing Change Detection: A review of current models and research directions},
	author       = {Chen Wu and Liangpei Zhang and Bo Du and Hongruixuan Chen and Jingxuan Wang and Huan Zhong},
	year         = 2024,
	journal      = {IEEE Geoscience and Remote Sensing Magazine},
	volume       = 12,
	pages        = {305--334},
	xurlx          = {https://api.semanticscholar.org/CorpusID:271624991}
}
@article{Liu2025NetworkAD,
	title        = {Network and Dataset for Multiscale Remote Sensing Image Change Detection},
	author       = {Shenbo Liu and Dongxue Zhao and Yuheng Zhou and Ying Tan and Huang He and Zhao Zhang and Lijun Tang},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 18,
	pages        = {2851--2866},
	xurlx          = {https://api.semanticscholar.org/CorpusID:275032911}
}
@article{dong_efficientcd_2024,
	title        = {EfficientCD: A New Strategy for Change Detection Based With Bi-Temporal Layers Exchanged},
	author       = {Sijun Dong and Yuwei Zhu and Geng Chen and Xiaoliang Meng},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--13},
	xurlx          = {https://api.semanticscholar.org/CorpusID:271334086}
}
@article{Fu2025BeyondCD,
	title        = {Beyond Cross-Temporal Difference: Style-Aligned and Fusion-Difference Learning for Change Detection},
	author       = {Siming Fu and Sijun Dong and Xiaoliang Meng},
	year         = 2025,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	xurlx          = {https://api.semanticscholar.org/CorpusID:279703915}
}
@article{Hang2024AANetAA,
	title        = {AANet: An Ambiguity-Aware Network for Remote-Sensing Image Change Detection},
	author       = {Renlong Hang and Siqi Xu and Panli Yuan and Qingshan Liu},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--11},
	xurlx          = {https://api.semanticscholar.org/CorpusID:268204920}
}
@article{Ma2024EATDerEA,
	title        = {EATDer: Edge-Assisted Adaptive Transformer Detector for Remote Sensing Change Detection},
	author       = {Jingjing Ma and Junyi Duan and Xu Tang and Xiangrong Zhang and Licheng Jiao},
	year         = 2024,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 62,
	pages        = {1--15},
	xurlx          = {https://api.semanticscholar.org/CorpusID:266368343}
}
@article{Liu2025FullScaleCD,
	title        = {Full-Scale Change Detection Network for Remote Sensing Images Based on Deep Feature Fusion},
	author       = {Shenbo Liu and Dongxue Zhao and Yuheng Zhou and Ying Tan and Huang He and Zhao Zhang and Lijun Tang},
	year         = 2025,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 63,
	pages        = {1--13},
	xurlx          = {https://api.semanticscholar.org/CorpusID:277397556}
}
@article{Lin2016FeaturePN,
	title        = {Feature Pyramid Networks for Object Detection},
	author       = {Tsung-Yi Lin and Piotr Doll{\'a}r and Ross B. Girshick and Kaiming He and Bharath Hariharan and Serge J. Belongie},
	year         = 2016,
	journal      = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {936--944},
	xurlx          = {https://api.semanticscholar.org/CorpusID:10716717}
}
@article{Pei2022FeatureHD,
	title        = {Feature Hierarchical Differentiation for Remote Sensing Image Change Detection},
	author       = {Gensheng Pei and Lulu Zhang},
	year         = 2022,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	volume       = 19,
	pages        = {1--5},
	xurlx          = {https://api.semanticscholar.org/CorpusID:251089099}
}
@article{Fang2022ChangerFI,
	title        = {Changer: Feature Interaction is What You Need for Change Detection},
	author       = {Sheng Fang and Kaiyu Li and Zhe Li},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 61,
	pages        = {1--11},
	xurlx          = {https://api.semanticscholar.org/CorpusID:252367220}
}
@article{Zhang2024B2CNetAP,
	title        = {B2CNet: A Progressive Change Boundary-to-Center Refinement Network for Multitemporal Remote Sensing Images Change Detection},
	author       = {Zhiqi Zhang and Liyang Bao and Shao Xiang and Guangqi Xie and Rong Gao},
	year         = 2024,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 17,
	pages        = {11322--11338},
	xurlx          = {https://api.semanticscholar.org/CorpusID:270272635}
}
@article{Zhang2025STRobustNetEC,
	title        = {STRobustNet: Efficient Change Detection via Spatial–Temporal Robust Representations in Remote Sensing},
	author       = {Hong Zhang and Yuhang Teng and Hao Yang Li and Zhihui Wang},
	year         = 2025,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 63,
	pages        = {1--15},
	xurlx          = {https://api.semanticscholar.org/CorpusID:276298966}
}
@article{DQXX202004022,
	title        = {面向地理国情监测的变化检测与地表覆盖信息更新方法},
	author       = {杜培军 and     王欣 and     蒙亚平 and     林聪 and     张鹏 and 卢刚},
	year         = 2020,
	journal      = {地球信息科学学报},
	volume       = 22,
	number       = {04},
	pages        = {857--866},
	issn         = {1560-8999}
}
@article{YGXB201203010,
	title        = {基于独立成分分析的高光谱变化检测},
	author       = {武辰 and     杜博 and 张良培},
	year         = 2012,
	journal      = {遥感学报},
	volume       = 16,
	number       = {03},
	pages        = {545--561},
	issn         = {1007-4619}
}
@article{Peng2025DeepLC,
	title        = {Deep learning change detection techniques for optical remote sensing imagery: Status, perspectives and challenges},
	author       = {Daifeng Peng and Xuelian Liu and Yongjun Zhang and Haiyan Guan and Yansheng Li and Lorenzo Bruzzone},
	year         = 2025,
	journal      = {Int. J. Appl. Earth Obs. Geoinformation},
	volume       = 136,
	pages        = 104282,
	xurlx          = {https://api.semanticscholar.org/CorpusID:274808788}
}
@article{Ding2025ASO,
	title        = {A Survey of Sample-Efficient Deep Learning for Change Detection in Remote Sensing: Tasks, Strategies, and Challenges},
	author       = {Lei Ding and Danfeng Hong and Maofan Zhao and Hongruixuan Chen and Chenyu Li and Jie Deng and Naoto Yokoya and Lorenzo Bruzzone and Jocelyn Chanussot},
	year         = 2025,
	journal      = {ArXiv},
	volume       = {abs/2502.02835},
	xurlx          = {https://api.semanticscholar.org/CorpusID:276116647}
}
@article{Bai2024ANU,
	title        = {A Novel UNet 3+ Change Detection Method Considering Scale Uncertainty in High-Resolution Imagery},
	author       = {Ting Bai and Qing An and Shiquan Deng and Pengfei Li and Yepei Chen and Kaiming Sun and Huajian Zheng and Zhina Song},
	year         = 2024,
	journal      = {Remote. Sens.},
	volume       = 16,
	pages        = 1846,
	xurlx          = {https://api.semanticscholar.org/CorpusID:269990705}
}
@article{Zhu2024VisionME,
	title        = {Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model},
	author       = {Lianghui Zhu and Bencheng Liao and Qian Zhang and Xinlong Wang and Wenyu Liu and Xinggang Wang},
	year         = 2024,
	journal      = {ArXiv},
	volume       = {abs/2401.09417},
	xurlx          = {https://api.semanticscholar.org/CorpusID:267028142}
}
@article{Caron2021EmergingPI,
	title        = {Emerging Properties in Self-Supervised Vision Transformers},
	author       = {Mathilde Caron and Hugo Touvron and Ishan Misra and Herv'e J'egou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
	year         = 2021,
	journal      = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {9630--9640},
	xurlx          = {https://api.semanticscholar.org/CorpusID:233444273}
}
@article{Han2024ParameterEfficientFF,
	title        = {Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey},
	author       = {Zeyu Han and Chao Gao and Jinyang Liu and Jeff Zhang and Sai Qian Zhang},
	year         = 2024,
	journal      = {Trans. Mach. Learn. Res.},
	volume       = 2024,
	xurlx          = {https://api.semanticscholar.org/CorpusID:268553763}
}
@article{Chen2022Res2UnetAN,
	title        = {Res2-Unet, a New Deep Architecture for Building Detection From High Spatial Resolution Images},
	author       = {Fangxiao Chen and Ning Wang and Bo Yu and Lei Wang},
	year         = 2022,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 15,
	pages        = {1494--1501},
	xurlx          = {https://api.semanticscholar.org/CorpusID:246369242}
}
@article{Ding2021BiTemporalSR,
	title        = {Bi-Temporal Semantic Reasoning for the Semantic Change Detection in HR Remote Sensing Images},
	author       = {Lei Ding and Haitao Guo and Sicong Liu and Lichao Mou and Jing Zhang and Lorenzo Bruzzone},
	year         = 2021,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	pages        = {1--14},
	xurlx          = {https://api.semanticscholar.org/CorpusID:237048202}
}
@article{Zhu2023EdgeGuidedPN,
	title        = {Edge-Guided Parallel Network for VHR Remote Sensing Image Change Detection},
	author       = {Ye Zhu and Kaikai Lv and Yang Yu and Wenjia Xu},
	year         = 2023,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 16,
	pages        = {7791--7803},
	xurlx          = {https://api.semanticscholar.org/CorpusID:260986373}
}
@article{Liang2024RaSRNetAE,
	title        = {RaSRNet: An End-to-End Relation-Aware Semantic Reasoning Network for Change Detection in Optical Remote Sensing Images},
	author       = {Yi Liang and Chengkun Zhang and Min Han},
	year         = 2024,
	journal      = {IEEE Transactions on Instrumentation and Measurement},
	volume       = 73,
	pages        = {1--11},
	xurlx          = {https://api.semanticscholar.org/CorpusID:257144650}
}
@article{Zhu2025Change3DRC,
	title        = {Change3D: Revisiting Change Detection and Captioning from A Video Modeling Perspective},
	author       = {Duowang Zhu and Xiaohu Huang and Haiyan Huang and Hao Zhou and Zhenfeng Shao},
	year         = 2025,
	journal      = {2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {24011--24022},
	xurlx          = {https://api.semanticscholar.org/CorpusID:277940747}
}
@article{Bandara2025DDPMCDDD,
	title        = {DDPM-CD: Denoising Diffusion Probabilistic Models as Feature Extractors for Remote Sensing Change Detection},
	author       = {W. G. C. Bandara and Nithin Gopalakrishnan Nair and Vishal M. Patel},
	year         = 2025,
	journal      = {2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
	pages        = {5250--5262},
	xurlx          = {https://api.semanticscholar.org/CorpusID:249953553}
}
@article{Oquab2023DINOv2LR,
	title        = {DINOv2: Learning Robust Visual Features without Supervision},
	author       = {Maxime Oquab and Timoth{\'e}e Darcet and Th{\'e}o Moutakanni and Huy Q. Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russ Howes and Po-Yao (Bernie) Huang and Shang-Wen Li and Ishan Misra and Michael G. Rabbat and Vasu Sharma and Gabriel Synnaeve and Huijiao Xu and Herv{\'e} J{\'e}gou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
	year         = 2023,
	journal      = {ArXiv},
	volume       = {abs/2304.07193},
	xurlx          = {https://api.semanticscholar.org/CorpusID:258170077}
}
@misc{simeoni2025dinov3,
	title        = {{DINOv3}},
	author       = {Sim{\'e}oni, Oriane and Vo, Huy V. and Seitzer, Maximilian and Baldassarre, Federico and Oquab, Maxime and Jose, Cijo and Khalidov, Vasil and Szafraniec, Marc and Yi, Seungeun and Ramamonjisoa, Micha{\"e}l and Massa, Francisco and Haziza, Daniel and Wehrstedt, Luca and Wang, Jianyuan and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Sentana, Leonel and Roberts, Claire and Vedaldi, Andrea and Tolan, Jamie and Brandt, John and Couprie, Camille and Mairal, Julien and J{\'e}gou, Herv{\'e} and Labatut, Patrick and Bojanowski, Piotr},
	year         = 2025,
	xurlx          = {https://arxiv.org/abs/2508.10104},
	eprint       = {2508.10104},
	archiveprefix = {arXiv},
	primaryclass = {cs.CV}
}
@article{multi-level,
	title        = {A Multilevel Encoder–Decoder Attention Network for Change Detection in Hyperspectral Images},
	author       = {Qu, Jiahui and Hou, Shaoxiong and Dong, Wenqian and Li, Yunsong and Xie, Weiying},
	year         = 2022,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 60,
	number       = {},
	pages        = {1--13},
	keywords     = {Feature extraction;Decoding;Convolutional neural networks;Task analysis;Fuses;Semantics;Deep learning;Attention mechanism;change detection (CD);deep learning (DL);hyperspectral image (HSI);multilevel features}
}
@article{Cnn-Trans,
	title        = {ConvTransNet: A CNN–Transformer Network for Change Detection With Multiscale Global–Local Representations},
	author       = {Li, Weiming and Xue, Lihui and Wang, Xueqian and Li, Gang},
	year         = 2023,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 61,
	number       = {},
	pages        = {1--15},
	doi          = {10.1109/TGRS.2023.3272694},
	keywords     = {Feature extraction;Transformers;Remote sensing;Optical sensors;Optical imaging;Convolution;Sensors;Change detection (CD);convolutional neural network (CNN);optical remote sensing image;Transformer}
}
@inproceedings{MCTNet,
	title        = {MCTNet: A Multi-Scale CNN-Transformer Network for Change Detection in Optical Remote Sensing Images},
	author       = {Li, Weiming and Xue, Lihui and Wang, Xueqian and Li, Gang},
	year         = 2023,
	booktitle    = {2023 26th International Conference on Information Fusion (FUSION)},
	volume       = {},
	number       = {},
	pages        = {1--5},
	doi          = {10.23919/FUSION52260.2023.10224182},
	keywords     = {Aggregates;Optical fiber networks;Feature extraction;Transformers;Optical imaging;Adaptive optics;Robustness;Change detection;convolutional neural network;transformer;remote sensing images}
}
@article{CBAM,
	title        = {A CBAM Based Multiscale Transformer Fusion Approach for Remote Sensing Image Change Detection},
	author       = {Wang, Wei and Tan, Xinai and Zhang, Peng and Wang, Xin},
	year         = 2022,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 15,
	number       = {},
	pages        = {6817--6825},
	doi          = {10.1109/JSTARS.2022.3198517},
	keywords     = {Transformers;Feature extraction;Remote sensing;Context modeling;Data mining;Semantics;Decoding;Change detection;convolutional block attention module (CBAM);multiscale;remote sensing;transformer}
}
@article{sparse_Atten,
	title        = {Change Detection in Remote-Sensing Images Using Pyramid Pooling Dynamic Sparse Attention Network With Difference Enhancement},
	author       = {Li, Zhong and Ouyang, Bin and Qiu, Shaohua and Xu, Xinghua and Cui, Xiaopeng and Hua, Xia},
	year         = 2024,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 17,
	number       = {},
	pages        = {7052--7067},
	doi          = {10.1109/JSTARS.2024.3374050},
	keywords     = {Feature extraction;Transformers;Semantics;Remote sensing;Computational modeling;Convolution;Data mining;Attention mechanism;change detection (CD);deep learning;remote sensing}
}
@inproceedings{Dynamic_encode,
	title        = {Dynamic Sparse Encoding and Cross-Temporal Attention for Remote Sensing Image Change Detection},
	author       = {Lin, Shaoxiong and Lei, Tao and Liu, Tongfei and Zhang, Shuxin and Min, Chongdan and Nandi, Asoke K.},
	year         = 2025,
	booktitle    = {ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	volume       = {},
	number       = {},
	pages        = {1--5},
	doi          = {10.1109/ICASSP49660.2025.10890539},
	keywords     = {Visualization;Image coding;Correlation;Computational modeling;Collaboration;Feature extraction;Transformers;Convolutional neural networks;Computational complexity;Remote sensing;remote sensing image;change detection;sparse encoding;collaborative attention;Transformer}
}
@article{ravi2024sam,
	title        = {Sam 2: Segment anything in images and videos},
	author       = {Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and others},
	year         = 2024,
	journal      = {arXiv preprint arXiv:2408.00714}
}
@inproceedings{yang2024depth,
	title        = {Depth anything: Unleashing the power of large-scale unlabeled data},
	author       = {Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
	year         = 2024,
	booktitle    = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages        = {10371--10381}
}
@article{yang2024depth2,
	title        = {Depth anything v2},
	author       = {Yang, Lihe and Kang, Bingyi and Huang, Zilong and Zhao, Zhen and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
	year         = 2024,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 37,
	pages        = {21875--21911}
}
@misc{LORA,
	title        = {LoRA: Low-Rank Adaptation of Large Language Models},
	author       = {Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
	year         = 2021,
	xurlx          = {https://arxiv.org/abs/2106.09685},
	eprint       = {2106.09685},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{adapter,
	title        = {Parameter-Efficient Transfer Learning for NLP},
	author       = {Neil Houlsby and Andrei Giurgiu and Stanislaw Jastrzebski and Bruna Morrone and Quentin de Laroussilhe and Andrea Gesmundo and Mona Attariyan and Sylvain Gelly},
	year         = 2019,
	xurlx          = {https://arxiv.org/abs/1902.00751},
	eprint       = {1902.00751},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@misc{prompt,
	title        = {The Power of Scale for Parameter-Efficient Prompt Tuning},
	author       = {Brian Lester and Rami Al-Rfou and Noah Constant},
	year         = 2021,
	xurlx          = {https://arxiv.org/abs/2104.08691},
	eprint       = {2104.08691},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{Zhou2021iBOTIB,
	title        = {iBOT: Image BERT Pre-Training with Online Tokenizer},
	author       = {Jinghao Zhou and Chen Wei and Huiyu Wang and Wei Shen and Cihang Xie and Alan Loddon Yuille and Tao Kong},
	year         = 2021,
	journal      = {ArXiv},
	volume       = {abs/2111.07832},
	xurlx          = {https://api.semanticscholar.org/CorpusID:244117494}
}
@article{Liu2022FewShotPF,
	title        = {Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning},
	author       = {Haokun Liu and Derek Tam and Mohammed Muqeeth and Jay Mohta and Tenghao Huang and Mohit Bansal and Colin Raffel},
	year         = 2022,
	journal      = {ArXiv},
	volume       = {abs/2205.05638},
	xurlx          = {https://api.semanticscholar.org/CorpusID:248693283}
}
@article{AGFormer,
	title        = {AGFormer: An anchor-guided transformer for class imbalance in remote sensing change detection},
	author       = {Jiaen Chen and Da Wu and Quanqing Ma and Shengjie Xu and Yuchen Zheng},
	year         = 2025,
	journal      = {Pattern Recognition},
	volume       = 168,
	pages        = 111839,
	doi          = {https://doi.org/10.1016/j.patcog.2025.111839},
	issn         = {0031-3203},
	xurlx          = {https://www.sciencedirect.com/science/article/pii/S0031320325004996},
	keywords     = {Change detection, Metric learning, Class anchors},
	abstract     = {Remote Sensing Change Detection (RSCD) aims to assess changes by comparing two or more images recorded for the same area but taken at different time stamps. Mainstream research improves the representation of models through the optimization of model architecture design, ignoring the importance of correcting classifiers. However, the issue of class imbalance in the RSCD field inevitably introduces biases into the classifier, damaging the model performance. In this paper, we propose an Anchor-Guided transFormer-based model, named AGFormer, to address this problem. Specifically, the HAR (Hypersphere Anchor Regularization) calibrates the classification layer from an anchor view, which ensures both inter-class separability and intra-class balance between compactness and diversity by initializing class anchors on the hypersphere and applying similarity-based contrastive learning in different phases. In addition, a disentanglement anchor optimization strategy is designed to avoid the influence of class imbalance in the RSCD field. By supervising the main features and calibrating classifiers with mapped class anchors, more discriminative representations and robust classifiers are obtained. In addition, we design the CEM (Change Enhancement Module) based on flow to highlight the changed features. The proposed HAR and CEM are plug-and-play and can be integrated into existing architectures. Extensive experiments are conducted on four benchmark datasets, and state-of-the-art performance is achieved by the proposed AGFormer. All the codes are available at https://github.com/jiaenchen2024/AGFormer.}
}
@article{AEGLNet,
	title        = {AEGL-Net: Adaptive Multiscale Global–Local Feature Fusion Network for Remote Sensing Change Detection},
	author       = {Ying, Zilu and Zhou, Yijun and Zhai, Yikui and Zhu, Hufei and Zhang, Hongsheng and Coscia, Pasquale and Genovese, Angelo and Scotti, Fabio and Piuri, Vincenzo and Philip Chen, C. L.},
	year         = 2025,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 63,
	number       = {},
	pages        = {1--19},
	doi          = {10.1109/TGRS.2025.3575591},
	keywords     = {Feature extraction;Remote sensing;Transformers;Context modeling;Data mining;Principal component analysis;Noise;Decoding;Adaptation models;Accuracy;Adaptive multiscale enhancement (AME);global-local feature fusion (GLFF);remote sensing change detection (RSCD)}
}
@article{Zhao2023AdaptingVT,
	title        = {Adapting Vision Transformer for Efficient Change Detection},
	author       = {Yang Zhao and Yuxiang Zhang and Yanni Dong and Bo Du},
	year         = 2023,
	journal      = {ArXiv},
	volume       = {abs/2312.04869},
	xurlx          = {https://api.semanticscholar.org/CorpusID:266149789}
}
@article{Chen2024ChangeDA,
	title        = {Change Dino: A Unified Transformer-Based Framework For Object-Level Change Detection and Segmentation in Remote Sensing Imagery},
	author       = {Yixin Chen and Ruiqian Zhang and Xiaogang Ning and Hanchao Zhang and Youxi He and Yuxing Xie and Jiaming Wang},
	year         = 2024,
	journal      = {IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium},
	pages        = {8585--8589},
	xurlx          = {https://api.semanticscholar.org/CorpusID:272432743}
}
@article{Ying2025AEGLNetAM,
	title        = {AEGL-Net: Adaptive Multiscale Global–Local Feature Fusion Network for Remote Sensing Change Detection},
	author       = {Zilu Ying and Yijun Zhou and Yikui Zhai and Hufei Zhu and Hongsheng Zhang and Pasquale Coscia and Angelo Genovese and Fabio Scotti and Vincenzo Piuri and C. L. Philip Chen},
	year         = 2025,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 63,
	pages        = {1--19},
	xurlx          = {https://api.semanticscholar.org/CorpusID:279096874}
}
@article{Chen2025AGFormerAA,
	title        = {AGFormer: An anchor-guided transformer for class imbalance in remote sensing change detection},
	author       = {Jiaen Chen and Da Wu and Quanqing Ma and Shengjie Xu and Yuchen Zheng},
	year         = 2025,
	journal      = {Pattern Recognit.},
	volume       = 168,
	pages        = 111839,
	xurlx          = {https://api.semanticscholar.org/CorpusID:278991383}
}
@article{Yang2025ConvFormerCDHC,
	title        = {ConvFormer-CD: Hybrid CNN–Transformer With Temporal Attention for Detecting Changes in Remote Sensing Imagery},
	author       = {Feng Yang and Mengtao Li and Wenqiang Shu and Anyong Qin and Tiecheng Song and Chenqiang Gao and Gui-Song Xia},
	year         = 2025,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 63,
	pages        = {1--15},
	xurlx          = {https://api.semanticscholar.org/CorpusID:276587808}
}
@article{Zhan2025DifferenceAwareMF,
	title        = {Difference-Aware Multiscale Feature Aggregation Network for Building Change Detection},
	author       = {Tao Zhan and Qiushi Tian and Yuanyuan Zhu and Jie Lan and Qianlong Dang and Maoguo Gong},
	year         = 2025,
	journal      = {IEEE Transactions on Geoscience and Remote Sensing},
	volume       = 63,
	pages        = {1--15},
	xurlx          = {https://api.semanticscholar.org/CorpusID:277848794}
}
@article{Huang2025LCCDMambaVS,
	title        = {LCCDMamba: Visual State Space Model for Land Cover Change Detection of VHR Remote Sensing Images},
	author       = {Jun Huang and Xiaochen Yuan and Chan Tong Lam and Yapeng Wang and Min Xia},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 18,
	pages        = {5765--5781},
	xurlx          = {https://api.semanticscholar.org/CorpusID:275776209}
}
@article{Liu2025CWmambaLC,
	title        = {CWmamba: Leveraging CNN-Mamba Fusion for Enhanced Change Detection in Remote Sensing Images},
	author       = {Yingchao Liu and Guangliang Cheng and Qihang Sun and Chunpeng Tian and Lukun Wang},
	year         = 2025,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	volume       = 22,
	pages        = {1--5},
	xurlx          = {https://api.semanticscholar.org/CorpusID:276819008}
}
@article{Zhang2025ADS,
	title        = {A Deep Supervised Change Detection Network Based on Context-Rich Information},
	author       = {Yanni Zhang and Lei Yang and Licai Zhu and Caigen Zhou and Yaser A. Nanehkaran and Jianzhong Wang},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	xurlx          = {https://api.semanticscholar.org/CorpusID:280779334}
}
@article{Li2025SAMMambaATC,
	title        = {SAM-Mamba:A Two-Stage Change Detection Network Combining the Adapting Segment Anything and Mamba models},
	author       = {Yutian Li and Wei Liu and Erzhu Li and Lianpeng Zhang and Xing Li},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	xurlx          = {https://api.semanticscholar.org/CorpusID:280764868}
}
@article{Li2025DifferenceEA,
	title        = {Difference Enhancement and Dependency-Aware Network for Remote Sensing Images Change Detection},
	author       = {Hongyun Li and Shuli Cheng and Anyu Du},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	xurlx          = {https://api.semanticscholar.org/CorpusID:280678210}
}
@article{Zhou2025DepthCDDP,
	title        = {DepthCD: Depth prompting in 2D remote sensing imagery change detection},
	author       = {Ning Zhou and Mingting Zhou and Haigang Sui},
	year         = 2025,
	journal      = {ISPRS Journal of Photogrammetry and Remote Sensing},
	xurlx          = {https://api.semanticscholar.org/CorpusID:279383174}
}
@article{Liu2025CDSTMambaTR,
	title        = {CD-STMamba: Toward Remote Sensing Image Change Detection With Spatio-Temporal Interaction Mamba Model},
	author       = {Shanwei Liu and Shuaipeng Wang and Wei Zhang and Tao Zhang and Mingming Xu and Muhammad Yasir and Shiqing Wei},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 18,
	pages        = {10471--10485},
	xurlx          = {https://api.semanticscholar.org/CorpusID:277705639}
}
@article{Huang2025SAMBasedEF,
	title        = {SAM-Based Efficient Feature Integration Network for Remote Sensing Change Detection: A Case Study on Macao Sea Reclamation},
	author       = {Jun Huang and Junqi Bao and Min Xia and Xiaochen Yuan},
	year         = 2025,
	journal      = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume       = 18,
	pages        = {16916--16928},
	xurlx          = {https://api.semanticscholar.org/CorpusID:279733460}
}
@article{Wu2024DIEFENDI,
  title={DIEFEN: Differential Information-Enhanced Feature Exchange Network for Hyperspectral Change Detection},
  author={Lanxin Wu and Lei Ma and Jiangtao Peng and Bin Yang and Weiwei Sun and Junhao Wang and Xinyu Luo},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  volume={62},
  pages={1-12},
  xurlx={https://api.semanticscholar.org/CorpusID:273016781}
}
@article{Ying2024DGMA2NetAD,
  title={DGMA2-Net: A Difference-Guided Multiscale Aggregation Attention Network for Remote Sensing Change Detection},
  author={Zilu Ying and Zijun Tan and Yikui Zhai and Xudong Jia and Wenba Li and Junying Zeng and Angelo Genovese and Vincenzo Piuri and Fabio Scotti},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  volume={62},
  pages={1-16},
  xurlx={https://api.semanticscholar.org/CorpusID:269219081}
}
@article{Chen2023AFC,
  title={A Full-Scale Connected CNN-Transformer Network for Remote Sensing Image Change Detection},
  author={Min Chen and Qiangjiang Zhang and Xuming Ge and Bo Xu and Han Hu and Qing Zhu and Xin Zhang},
  journal={Remote. Sens.},
  year={2023},
  volume={15},
  pages={5383},
  xurlx={https://api.semanticscholar.org/CorpusID:265321991}
}
@article{Li2023ConvTransNetAC,
  title={ConvTransNet: A CNN–Transformer Network for Change Detection With Multiscale Global–Local Representations},
  author={Weiming Li and Lihui Xue and Xueqian Wang and Gang Li},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2023},
  volume={61},
  pages={1-15},
  xurlx={https://api.semanticscholar.org/CorpusID:258495122}
}
@article{YGXB202309001,
author = {  柳思聪 and     都科丞 and     郑永杰 and     陈晋 and     杜培军 and 童小华},
title = {人工智能时代的遥感变化检测技术：继承、发展与挑战},
journal = {遥感学报},
volume = {27},
number = {09},
pages = {1975-1987},
year = {2023},
issn = {1007-4619},
}    
@article{YGXB202407012,
author = {  张奇 and     路遥 and     王飞 and     张雪涛 and 郑南宁},
title = {基于实例对比学习的遥感建筑物变化检测域适应算法},
journal = {遥感学报},
volume = {28},
number = {07},
pages = {1771-1788},
year = {2024},
issn = {1007-4619},
}    
